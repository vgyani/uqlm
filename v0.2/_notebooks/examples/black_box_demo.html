
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" sizes="16x16" href="../../_static/images/favicon/favicon-16x16.png" type="image/png">
    <link rel="icon" sizes="32x32" href="../../_static/images/favicon/favicon-32x32.png" type="image/png">
    <link rel="apple-touch-icon" sizes="180x180" href="../../_static/images/favicon/apple-touch-icon.png" type="image/png">
    <title>üéØ Black-Box Uncertainty Quantification &#8212; uqlm 0.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=662d8ef6" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=10f1778b"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "displayMath": [["$$", "$$"], ["\\[", "\\]"]]}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_notebooks/examples/black_box_demo';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://cvs-health.github.io/uqlm/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.2';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="üéØ Multimodal Uncertainty Quantification" href="multimodal_demo.html" />
    <link rel="prev" title="üéØ White-Box Uncertainty Quantification" href="white_box_single_generation_demo.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/horizontal_logo.png" class="logo__image only-light" alt="uqlm 0.2 documentation - Home"/>
    <img src="../../_static/horizontal_logo_no_bg.png" class="logo__image only-dark pst-js-only" alt="uqlm 0.2 documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../scorer_definitions/index.html">
    Scorer Definitions
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../scorer_definitions/index.html">
    Scorer Definitions
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ensemble_off_the_shelf_demo.html">üéØ BS Detector: Off-the-Shelf Ensemble for LLM Uncertainty</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensemble_tuning_demo.html">üéØ Tunable Ensemble for LLM Uncertainty (Advanced)</a></li>
<li class="toctree-l1"><a class="reference internal" href="judges_demo.html">üéØ LLM-as-a-Judge</a></li>
<li class="toctree-l1"><a class="reference internal" href="semantic_entropy_demo.html">üéØ Semantic Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="semantic_density_demo.html">üéØ Semantic Density</a></li>
<li class="toctree-l1"><a class="reference internal" href="white_box_multi_generation_demo.html">üéØ White-Box Uncertainty Quantification</a></li>
<li class="toctree-l1"><a class="reference internal" href="white_box_single_generation_demo.html">üéØ White-Box Uncertainty Quantification</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">üéØ Black-Box Uncertainty Quantification</a></li>
<li class="toctree-l1"><a class="reference internal" href="multimodal_demo.html">üéØ Multimodal Uncertainty Quantification</a></li>
<li class="toctree-l1"><a class="reference internal" href="score_calibration_demo.html">üéØ Confidence Score Calibration Demo</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Example Notebooks</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">üéØ Black-Box Uncertainty Quantification</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="üéØ-Black-Box-Uncertainty-Quantification">
<h1>üéØ Black-Box Uncertainty Quantification<a class="headerlink" href="#üéØ-Black-Box-Uncertainty-Quantification" title="Link to this heading">#</a></h1>
<div style="background-color: rgba(200, 200, 200, 0.1); padding: 20px; border-radius: 8px; margin-bottom: 20px; border: 1px solid rgba(127, 127, 127, 0.2); max-width: 97.5%; overflow-wrap: break-word;"><p style="font-size: 16px; line-height: 1.6"><p>Black-box Uncertainty Quantification (UQ) methods treat the LLM as a black box and evaluate consistency of multiple responses generated from the same prompt to estimate response-level confidence. This demo provides an illustration of how to use state-of-the-art black-box UQ methods with uqlm. The available scorers and papers from which they are adapted are below:</p>
</p><ul class="simple">
<li><p>Discrete Semantic Entropy (<a class="reference external" href="https://www.nature.com/articles/s41586-024-07421-0">Farquhar et al., 2024</a>; <a class="reference external" href="https://arxiv.org/pdf/2302.09664">Kuhn et al., 2023</a>)</p></li>
<li><p>Number of Semantic Sets (<a class="reference external" href="https://arxiv.org/abs/2305.19187">Lin et al., 2024</a>; <a class="reference external" href="https://arxiv.org/abs/2406.15627">Vashurin et al., 2025</a>; <a class="reference external" href="https://arxiv.org/pdf/2302.09664">Kuhn et al., 2023</a>)</p></li>
<li><p>Non-Contradiction Probability (<a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>; <a class="reference external" href="https://arxiv.org/abs/2305.19187">Lin et al., 2024</a>; <a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>)</p></li>
<li><p>Entailment Probability (<a class="reference external" href="https://arxiv.org/abs/2305.19187">Lin et al., 2025</a>; <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>)</p></li>
<li><p>Exact Match (<a class="reference external" href="https://arxiv.org/abs/2305.14613">Cole et al., 2023</a>; <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>)</p></li>
<li><p>BERTScore (<a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>; <a class="reference external" href="https://arxiv.org/abs/1904.09675">Zheng et al., 2020</a>)</p></li>
<li><p>Normalized Cosine Similarity (<a class="reference external" href="https://arxiv.org/pdf/2412.05563">Shorinwa et al., 2024</a>; <a class="reference external" href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">HuggingFace</a>)</p></li>
</ul>
</div><section id="üìä-What-You'll-Do-in-This-Demo">
<h2>üìä What You‚Äôll Do in This Demo<a class="headerlink" href="#üìä-What-You'll-Do-in-This-Demo" title="Link to this heading">#</a></h2>
<div style="display: flex; margin-bottom: 15px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>1</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Set up LLM and prompts.</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Set up LLM instance and load example data prompts.</p>
</p></div></div><div style="display: flex; margin-bottom: 15px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>2</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Generate LLM Responses and Confidence Scores</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Generate and score LLM responses to the example questions using the BlackBoxUQ() class.</p>
</p></div></div><div style="display: flex; margin-bottom: 25px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>3</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Evaluate Hallucination Detection Performance</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Visualize model accuracy at different thresholds of the various black-box UQ confidence scores. Compute precision, recall, and F1-score of hallucination detection.</p>
</p></div></div></section>
<section id="‚öñÔ∏è-Advantages-&amp;-Limitations">
<h2>‚öñÔ∏è Advantages &amp; Limitations<a class="headerlink" href="#‚öñÔ∏è-Advantages-&-Limitations" title="Link to this heading">#</a></h2>
<div style="display: flex; gap: 20px"><div style="flex: 1; background-color: rgba(0, 200, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(0, 200, 0, 0.2)"><h3 style="color: #2e8b57; margin-top: 0"><p>Pros</p>
</h3><ul style="margin-bottom: 0"><li><p>Universal Compatibility: Works with any LLM</p>
</li><li><p>Intuitive: Easy to understand and implement</p>
</li><li><p>No Internal Access Required: Doesn‚Äôt need token probabilities or model internals</p>
</li></ul></div><div style="flex: 1; background-color: rgba(200, 0, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(200, 0, 0, 0.2)"><h3 style="color: #b22222; margin-top: 0"><p>Cons</p>
</h3><ul style="margin-bottom: 0"><li><p>Higher Cost: Requires multiple generations per prompt</p>
</li><li><p>Slower: Multiple generations and comparison calculations increase latency</p>
</li></ul></div></div><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm</span><span class="w"> </span><span class="kn">import</span> <span class="n">BlackBoxUQ</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_example_dataset</span><span class="p">,</span> <span class="n">plot_model_accuracies</span><span class="p">,</span> <span class="n">LLMGrader</span><span class="p">,</span> <span class="n">Tuner</span>
</pre></div>
</div>
</div>
</section>
<section id="1.-Set-up-LLM-and-Prompts">
<h2>1. Set up LLM and Prompts<a class="headerlink" href="#1.-Set-up-LLM-and-Prompts" title="Link to this heading">#</a></h2>
<p>In this demo, we will illustrate this approach using a set of short answer questions from the <a class="reference external" href="https://arxiv.org/abs/2212.10511">PopQA benchmark</a>. To implement with your use case, simply <strong>replace the example prompts with your data</strong>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load example dataset (popqa)</span>
<span class="n">popqa</span> <span class="o">=</span> <span class="n">load_example_dataset</span><span class="p">(</span><span class="s2">&quot;popqa&quot;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">popqa</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading dataset - popqa...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Repo card metadata block was not found. Setting CardData to empty.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Processing dataset...
Dataset ready!
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>question</th>
      <th>answer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>What is George Rankin's occupation?</td>
      <td>[politician, political leader, political figur...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>What is John Mayne's occupation?</td>
      <td>[journalist, journo, journalists]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>What is Henry Feilden's occupation?</td>
      <td>[politician, political leader, political figur...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>What is Kathy Saltzman's occupation?</td>
      <td>[politician, political leader, political figur...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>What is Eleanor Davis's occupation?</td>
      <td>[cartoonist, graphic artist, animator, illustr...</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define prompts</span>
<span class="n">INSTRUCTION</span> <span class="o">=</span> <span class="s2">&quot;You will be given a question. Return only the answer as concisely as possible without providing an explanation.</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">INSTRUCTION</span> <span class="o">+</span> <span class="n">prompt</span> <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">popqa</span><span class="o">.</span><span class="n">question</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>In this example, we use <code class="docutils literal notranslate"><span class="pre">AzureChatOpenAI</span></code> to instantiate our LLM, but any <a class="reference external" href="https://js.langchain.com/docs/integrations/chat/">LangChain Chat Model</a> may be used. Be sure to <strong>replace with your LLM of choice.</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import sys</span>
<span class="c1"># !{sys.executable} -m pip install langchain-openai</span>

<span class="c1">## User to populate .env file with API credentials</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span><span class="p">,</span> <span class="n">find_dotenv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">AzureChatOpenAI</span>

<span class="n">load_dotenv</span><span class="p">(</span><span class="n">find_dotenv</span><span class="p">())</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">AzureChatOpenAI</span><span class="p">(</span>
    <span class="n">deployment_name</span><span class="o">=</span><span class="s2">&quot;o3-mini&quot;</span><span class="p">,</span>
    <span class="n">openai_api_type</span><span class="o">=</span><span class="s2">&quot;azure&quot;</span><span class="p">,</span>
    <span class="n">openai_api_version</span><span class="o">=</span><span class="s2">&quot;2024-12-01-preview&quot;</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># User to set temperature</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="2.-Generate-LLM-Responses-and-Confidence-Scores">
<h2>2. Generate LLM Responses and Confidence Scores<a class="headerlink" href="#2.-Generate-LLM-Responses-and-Confidence-Scores" title="Link to this heading">#</a></h2>
<section id="BlackBoxUQ()---Generate-LLM-responses-and-compute-consistency-based-confidence-scores-for-each-response.">
<h3><code class="docutils literal notranslate"><span class="pre">BlackBoxUQ()</span></code> - Generate LLM responses and compute consistency-based confidence scores for each response.<a class="headerlink" href="#BlackBoxUQ()---Generate-LLM-responses-and-compute-consistency-based-confidence-scores-for-each-response." title="Link to this heading">#</a></h3>
<p><img alt="Sample Image" src="https://raw.githubusercontent.com/cvs-health/uqlm/develop/assets/images/black_box_graphic.png" /></p>
<section id="üìã-Class-Attributes">
<h4>üìã Class Attributes<a class="headerlink" href="#üìã-Class-Attributes" title="Link to this heading">#</a></h4>
<table style="border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);"><tr><th style="background-color: rgba(200, 200, 200, 0.2); width: 20%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Parameter</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Type &amp; Default</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 55%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Description</p>
</th></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>llm</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BaseChatModeldefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>A langchain llm <code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code>. User is responsible for specifying temperature and other relevant parameters to the constructor of the provided <code class="docutils literal notranslate"><span class="pre">llm</span></code> object.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>scorers</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>List[str]default=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies which black box (consistency) scorers to include. Must be subset of [‚Äòsemantic_negentropy‚Äô, ‚Äònoncontradiction‚Äô, ‚Äòexact_match‚Äô, ‚Äòbert_score‚Äô, ‚Äòcosine_sim‚Äô, ‚Äòentailment‚Äô, ‚Äòsemantic_sets_confidence‚Äô]. If None, defaults to [‚Äúsemantic_negentropy‚Äù, ‚Äúnoncontradiction‚Äù, ‚Äúexact_match‚Äù, ‚Äúcosine_sim‚Äù]. Note that using ‚Äúbleurt‚Äù is deprecated as of v0.2.0.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>device</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>str or torch.devicedefault=‚Äùcpu‚Äù</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies the device that NLI model use for prediction. Only applies to ‚Äòsemantic_negentropy‚Äô, ‚Äònoncontradiction‚Äô scorers. Pass a torch.device to leverage GPU.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>use_best</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>booldefault=True</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies whether to swap the original response for the uncertainty-minimized response among all sampled responses based on semantic entropy clusters. Only used if <code class="docutils literal notranslate"><span class="pre">scorers</span></code> includes ‚Äòsemantic_negentropy‚Äô or ‚Äònoncontradiction‚Äô.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>system_prompt</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>str or Nonedefault=‚ÄùYou are a helpful assistant.‚Äù</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Optional argument for user to provide custom system prompt for the LLM.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>max_calls_per_min</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>intdefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies how many API calls to make per minute to avoid rate limit errors. By default, no limit is specified.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>use_n_param</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>booldefault=False</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies whether to use n parameter for BaseChatModel. Not compatible with all BaseChatModel classes. If used, it speeds up the generation process substantially when num_responses is large.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>postprocessor</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>callabledefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>A user-defined function that takes a string input and returns a string. Used for postprocessing outputs.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>sampling_temperature</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>floatdefault=1</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>The ‚Äòtemperature‚Äô parameter for LLM to use when generating sampled LLM responses. Must be greater than 0.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>nli_model_name</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>strdefault=‚Äùmicrosoft/deberta-large-mnli‚Äù</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies which NLI model to use. Must be acceptable input to AutoTokenizer.from_pretrained() and AutoModelForSequenceClassification.from_pretrained().</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>max_length</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>intdefault=2000</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies the maximum allowed string length for LLM responses for NLI computation. Responses longer than this value will be truncated in NLI computations to avoid OutOfMemoryError.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>return_responses</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>strdefault=‚Äùall‚Äù</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>If a postprocessor is used, specifies whether to return only postprocessed responses, only raw responses, or both. Specified with ‚Äòpostprocessed‚Äô, ‚Äòraw‚Äô, or ‚Äòall‚Äô, respectively.</p>
</td></tr></table></section>
<section id="üîç-Parameter-Groups">
<h4>üîç Parameter Groups<a class="headerlink" href="#üîç-Parameter-Groups" title="Link to this heading">#</a></h4>
<div style="display: flex; gap: 20px; margin-bottom: 20px"><div style="flex: 1; padding: 10px; background-color: rgba(0, 100, 200, 0.1); border-radius: 5px; border: 1px solid rgba(0, 100, 200, 0.2);"><p style="font-weight: bold"><p>üß† LLM-Specific</p>
</p><ul><li><p>llm</p>
</li><li><p>system_prompt</p>
</li><li><p>sampling_temperature</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(0, 200, 0, 0.1); border-radius: 5px; border: 1px solid rgba(0, 200, 0, 0.2);"><p style="font-weight: bold"><p>üìä Confidence Scores</p>
</p><ul><li><p>scorers</p>
</li><li><p>use_best</p>
</li><li><p>nli_model_name</p>
</li><li><p>postprocessor</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(200, 150, 0, 0.1); border-radius: 5px; border: 1px solid rgba(200, 150, 0, 0.2);"><p style="font-weight: bold"><p>üñ•Ô∏è Hardware</p>
</p><ul><li><p>device</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(200, 0, 200, 0.1); border-radius: 5px; border: 1px solid rgba(200, 0, 200, 0.2);"><p style="font-weight: bold"><p>‚ö° Performance</p>
</p><ul><li><p>max_calls_per_min</p>
</li><li><p>use_n_param</p>
</li></ul></div></div></section>
<section id="üíª-Usage-Examples">
<h4>üíª Usage Examples<a class="headerlink" href="#üíª-Usage-Examples" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Basic usage with default parameters</span>
<span class="n">bbuq</span> <span class="o">=</span> <span class="n">BlackBoxUQ</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>

<span class="c1"># Using GPU acceleration, default scorers</span>
<span class="n">bbuq</span> <span class="o">=</span> <span class="n">BlackBoxUQ</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>

<span class="c1"># Custom scorer list</span>
<span class="n">bbuq</span> <span class="o">=</span> <span class="n">BlackBoxUQ</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;semantic_negentropy&quot;</span><span class="p">,</span> <span class="s2">&quot;exact_match&quot;</span><span class="p">,</span> <span class="s2">&quot;cosine_sim&quot;</span><span class="p">])</span>

<span class="c1"># High-throughput configuration with rate limiting</span>
<span class="n">bbuq</span> <span class="o">=</span> <span class="n">BlackBoxUQ</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">max_calls_per_min</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">use_n_param</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Set the torch device</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>  <span class="c1"># NVIDIA GPU</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>  <span class="c1"># macOS</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>  <span class="c1"># CPU</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="si">}</span><span class="s2"> device&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using cuda device
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">black_box_scorers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;noncontradiction&quot;</span><span class="p">,</span> <span class="s2">&quot;semantic_negentropy&quot;</span><span class="p">,</span> <span class="s2">&quot;cosine_sim&quot;</span><span class="p">]</span>
<span class="n">bbuq</span> <span class="o">=</span> <span class="n">BlackBoxUQ</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">max_calls_per_min</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="n">black_box_scorers</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="üîÑ-Class-Methods">
<h3>üîÑ Class Methods<a class="headerlink" href="#üîÑ-Class-Methods" title="Link to this heading">#</a></h3>
<table style="border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);"><tr><th style="background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Method</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 75%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Description &amp; Parameters</p>
</th></tr><tr><td style="font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BlackBoxUQ.generate_and_score</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p><p>Generate LLM responses, sampled LLM (candidate) responses, and compute confidence scores for the provided prompts.</p>
</p><p><p>Parameters:</p>
</p><ul><li><p>prompts - (List[str] or List[List[BaseMessage]]) A list of input prompts for the model.</p>
</li><li><p>num_responses - (int, default=5) The number of sampled responses used to compute consistency.</p>
</li><li><p>show_progress_bars - (bool, default=True) If True, displays a progress bar while generating and scoring responses.</p>
</li></ul><p><p>Returns: UQResult containing data (prompts, responses, sampled responses, and confidence scores) and metadata</p>
</p><div style="background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;"><p>üí° Best For: Complete end-to-end uncertainty quantification when starting with prompts.</p>
</div></td></tr><tr><td style="font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BlackBoxUQ.score</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p><p>Compute confidence scores on provided LLM responses. Should only be used if responses and sampled responses are already generated.</p>
</p><p><p>Parameters:</p>
</p><ul><li><p>responses - (List[str]) A list of LLM responses for the prompts.</p>
</li><li><p>sampled_responses - (List[List[str]]) A list of lists of sampled LLM responses for each prompt. Used to compute consistency scores by comparing to the corresponding response from responses.</p>
</li><li><p>show_progress_bars - (bool, default=True) If True, displays a progress bar while scoring responses.</p>
</li></ul><p><p>Returns: UQResult containing data (responses, sampled responses, and confidence scores) and metadata</p>
</p><div style="background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;"><p>üí° Best For: Computing uncertainty scores when responses are already generated elsewhere.</p>
</div></td></tr></table><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">bbuq</span><span class="o">.</span><span class="n">generate_and_score</span><span class="p">(</span>
    <span class="n">prompts</span><span class="o">=</span><span class="n">prompts</span><span class="p">,</span>
    <span class="n">num_responses</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># choose num_responses based on cost and latency requirements (higher means better hallucination detection but more cost and latency)</span>
<span class="p">)</span>

<span class="c1"># # alternative approach: directly score if responses already generated</span>
<span class="c1"># results = bbuq.score(responses=responses, sampled_responses=sampled_responses, show_progress_bars=True)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "15ae61270eeb4ac0be32ffbcc1dae85f", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result_df</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>response</th>
      <th>sampled_responses</th>
      <th>prompt</th>
      <th>cosine_sim</th>
      <th>semantic_negentropy</th>
      <th>noncontradiction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Film director.</td>
      <td>[Insufficient information., Film director., Jo...</td>
      <td>You will be given a question. Return only the ...</td>
      <td>0.782648</td>
      <td>0.435525</td>
      <td>0.558754</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Poet.</td>
      <td>[Poet., Poet., Poet., Poet., Poet.]</td>
      <td>You will be given a question. Return only the ...</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>British Conservative politician.</td>
      <td>[British Conservative politician., British Con...</td>
      <td>You will be given a question. Return only the ...</td>
      <td>0.954752</td>
      <td>1.000000</td>
      <td>0.999006</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Journalist.</td>
      <td>[Radio host., Author, Television journalist., ...</td>
      <td>You will be given a question. Return only the ...</td>
      <td>0.882440</td>
      <td>0.515804</td>
      <td>0.650505</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cartoonist.</td>
      <td>[Cartoonist., Cartoonist., Cartoonist., Cartoo...</td>
      <td>You will be given a question. Return only the ...</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
</section>
<section id="3.-Evaluate-Hallucination-Detection-Performance">
<h2>3. Evaluate Hallucination Detection Performance<a class="headerlink" href="#3.-Evaluate-Hallucination-Detection-Performance" title="Link to this heading">#</a></h2>
<p>To evaluate hallucination detection performance, we ‚Äògrade‚Äô the responses against an answer key. Here, we use UQLM‚Äôs out-of-the-box LLM Grader, which can be used with <a class="reference external" href="https://js.langchain.com/docs/integrations/chat/">LangChain Chat Model</a>, but you may replace this with a grading method of your choice. Some notable alternatives are <a class="reference external" href="https://huggingface.co/vectara/hallucination_evaluation_model">Vectara HHEM</a> and <a class="reference external" href="https://github.com/yuh-zha/AlignScore">AlignScore</a>. <strong>If you are using
your own prompts/questions, be sure to update the grading method accordingly</strong>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up the LLM grader</span>
<span class="n">gpt4o_mini</span> <span class="o">=</span> <span class="n">AzureChatOpenAI</span><span class="p">(</span><span class="n">deployment_name</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span> <span class="n">openai_api_type</span><span class="o">=</span><span class="s2">&quot;azure&quot;</span><span class="p">,</span> <span class="n">openai_api_version</span><span class="o">=</span><span class="s2">&quot;2024-02-15-preview&quot;</span><span class="p">)</span>
<span class="n">grader</span> <span class="o">=</span> <span class="n">LLMGrader</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">gpt4o_mini</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># grade orinal responses against the answer key using the grader</span>
<span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;response_correct&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="k">await</span> <span class="n">grader</span><span class="o">.</span><span class="n">grade_responses</span><span class="p">(</span><span class="n">prompts</span><span class="o">=</span><span class="n">popqa</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">(),</span> <span class="n">responses</span><span class="o">=</span><span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">(),</span> <span class="n">answers</span><span class="o">=</span><span class="n">popqa</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
<span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">popqa</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>response</th>
      <th>sampled_responses</th>
      <th>prompt</th>
      <th>cosine_sim</th>
      <th>semantic_negentropy</th>
      <th>noncontradiction</th>
      <th>response_correct</th>
      <th>answer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Film director.</td>
      <td>[Insufficient information., Film director., Jo...</td>
      <td>You will be given a question. Return only the ...</td>
      <td>0.782648</td>
      <td>0.435525</td>
      <td>0.558754</td>
      <td>False</td>
      <td>[politician, political leader, political figur...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Poet.</td>
      <td>[Poet., Poet., Poet., Poet., Poet.]</td>
      <td>You will be given a question. Return only the ...</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>False</td>
      <td>[journalist, journo, journalists]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>British Conservative politician.</td>
      <td>[British Conservative politician., British Con...</td>
      <td>You will be given a question. Return only the ...</td>
      <td>0.954752</td>
      <td>1.000000</td>
      <td>0.999006</td>
      <td>True</td>
      <td>[politician, political leader, political figur...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Journalist.</td>
      <td>[Radio host., Author, Television journalist., ...</td>
      <td>You will be given a question. Return only the ...</td>
      <td>0.882440</td>
      <td>0.515804</td>
      <td>0.650505</td>
      <td>False</td>
      <td>[politician, political leader, political figur...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cartoonist.</td>
      <td>[Cartoonist., Cartoonist., Cartoonist., Cartoo...</td>
      <td>You will be given a question. Return only the ...</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>True</td>
      <td>[cartoonist, graphic artist, animator, illustr...</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;Baseline LLM accuracy: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;response_correct&quot;</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Baseline LLM accuracy: 0.57
</pre></div></div>
</div>
<p>Here, we explore ‚Äòfiltered accuracy‚Äô as a metric for evaluating the performance of our confidence scores. Filtered accuracy measures the change in LLM performance when responses with confidence scores below a specified threshold are excluded. By adjusting the confidence score threshold, we can observe how the accuracy of the LLM improves as less certain responses are filtered out.</p>
<p>We will plot the filtered accuracy across various confidence score thresholds to visualize the relationship between confidence and LLM accuracy. This analysis helps in understanding the trade-off between response coverage (measured by sample size below) and LLM accuracy, providing insights into the reliability of the LLM‚Äôs outputs. We conduct this analysis separately for each of our scorers.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">confidence_score</span> <span class="ow">in</span> <span class="n">black_box_scorers</span><span class="p">:</span>
    <span class="n">plot_model_accuracies</span><span class="p">(</span><span class="n">scores</span><span class="o">=</span><span class="n">result_df</span><span class="p">[</span><span class="n">confidence_score</span><span class="p">],</span> <span class="n">correct_indicators</span><span class="o">=</span><span class="n">result_df</span><span class="o">.</span><span class="n">response_correct</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;LLM Accuracy by </span><span class="si">{</span><span class="n">confidence_score</span><span class="si">}</span><span class="s2"> Threshold&quot;</span><span class="p">,</span> <span class="n">display_percentage</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_black_box_demo_22_0.png" src="../../_images/_notebooks_examples_black_box_demo_22_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_black_box_demo_22_1.png" src="../../_images/_notebooks_examples_black_box_demo_22_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_black_box_demo_22_2.png" src="../../_images/_notebooks_examples_black_box_demo_22_2.png" />
</div>
</div>
<p>Lastly, we compute the optimal threshold for binarizing confidence scores, using F1-score as the objective. Using this threshold, we compute precision, recall, and F1-score for black box scorer predictions of whether responses are correct.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate UQLM tuner object for threshold selection</span>
<span class="n">split</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">Tuner</span><span class="p">()</span>

<span class="n">correct_indicators</span> <span class="o">=</span> <span class="p">(</span><span class="n">result_df</span><span class="o">.</span><span class="n">response_correct</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span>  <span class="c1"># Whether responses is actually correct</span>
<span class="n">metric_values</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Precision&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;Recall&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;F1-score&quot;</span><span class="p">:</span> <span class="p">[]}</span>
<span class="n">optimal_thresholds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">confidence_score</span> <span class="ow">in</span> <span class="n">bbuq</span><span class="o">.</span><span class="n">scorers</span><span class="p">:</span>
    <span class="c1"># tune threshold on first half</span>
    <span class="n">y_scores</span> <span class="o">=</span> <span class="n">result_df</span><span class="p">[</span><span class="n">confidence_score</span><span class="p">]</span>
    <span class="n">y_scores_tune</span> <span class="o">=</span> <span class="n">y_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">split</span><span class="p">]</span>
    <span class="n">y_true_tune</span> <span class="o">=</span> <span class="n">correct_indicators</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">split</span><span class="p">]</span>
    <span class="n">best_threshold</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">tune_threshold</span><span class="p">(</span><span class="n">y_scores</span><span class="o">=</span><span class="n">y_scores_tune</span><span class="p">,</span> <span class="n">correct_indicators</span><span class="o">=</span><span class="n">y_true_tune</span><span class="p">,</span> <span class="n">thresh_objective</span><span class="o">=</span><span class="s2">&quot;fbeta_score&quot;</span><span class="p">)</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[(</span><span class="n">s</span> <span class="o">&gt;</span> <span class="n">best_threshold</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">y_scores</span><span class="p">]</span>  <span class="c1"># predicts whether response is correct based on confidence score</span>
    <span class="n">optimal_thresholds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_threshold</span><span class="p">)</span>

    <span class="c1"># evaluate on last half</span>
    <span class="n">y_true_eval</span> <span class="o">=</span> <span class="n">correct_indicators</span><span class="p">[</span><span class="n">split</span><span class="p">:]</span>
    <span class="n">y_pred_eval</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">split</span><span class="p">:]</span>
    <span class="n">metric_values</span><span class="p">[</span><span class="s2">&quot;Precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true_eval</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred_eval</span><span class="p">))</span>
    <span class="n">metric_values</span><span class="p">[</span><span class="s2">&quot;Recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true_eval</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred_eval</span><span class="p">))</span>
    <span class="n">metric_values</span><span class="p">[</span><span class="s2">&quot;F1-score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true_eval</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred_eval</span><span class="p">))</span>

<span class="c1"># print results</span>
<span class="n">header</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Metrics&#39;</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scorer_name</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">scorer_name</span> <span class="ow">in</span> <span class="n">bbuq</span><span class="o">.</span><span class="n">scorers</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">header</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">header</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">header</span><span class="p">))</span>
<span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metric_values</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">metric_values</span><span class="p">[</span><span class="n">metric</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">header</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;F-1 optimal threshold&#39;</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">optimal_thresholds</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">header</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
====================================================================================================
Metrics                  noncontradiction         semantic_negentropy      cosine_sim
----------------------------------------------------------------------------------------------------
Precision                0.726                    0.619                    0.633
Recall                   0.818                    0.945                    0.909
F1-score                 0.769                    0.748                    0.746
----------------------------------------------------------------------------------------------------
F-1 optimal threshold    0.95                     0.52                     0.88
====================================================================================================
</pre></div></div>
</div>
</section>
<section id="4.-Scorer-Definitions">
<h2>4. Scorer Definitions<a class="headerlink" href="#4.-Scorer-Definitions" title="Link to this heading">#</a></h2>
<p>Below we define the scorers offered by the <code class="docutils literal notranslate"><span class="pre">BlackBoxUQ</span></code> class. These scorers exploit variation in LLM responses to the same prompt to measure semantic consistency. These scorers are adapted from the uncertainty quantification literature and have been transformed and normalized, as needed, to have outputs ranging from 0 to 1, where higher values indicate higher confidence.</p>
<p>For a given prompt <span class="math notranslate nohighlight">\(x_i\)</span>, these approaches involves generating <span class="math notranslate nohighlight">\(m\)</span> responses <span class="math notranslate nohighlight">\(\tilde{\mathbf{y}}_i = \{ \tilde{y}_{i1},...,\tilde{y}_{im}\}\)</span>, using a non-zero temperature, from the same prompt and comparing these responses to the original response <span class="math notranslate nohighlight">\(y_{i}\)</span>. We provide detailed descriptions of each below.</p>
<section id="Exact-Match-Rate-(exact_match)">
<h3>Exact Match Rate (<code class="docutils literal notranslate"><span class="pre">exact_match</span></code>)<a class="headerlink" href="#Exact-Match-Rate-(exact_match)" title="Link to this heading">#</a></h3>
<p>Exact Match Rate (EMR) computes the proportion of candidate responses that are identical to the original response.</p>
<div class="math notranslate nohighlight">
\[EMR(y_i; \tilde{\mathbf{y}}_i) = \frac{1}{m} \sum_{j=1}^m \mathbb{I}(y_i=\tilde{y}_{ij}).\]</div>
<p>For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2305.14613">Cole et al., 2023</a>.</p>
</section>
<section id="Non-Contradiction-Probability-(noncontradiction)">
<h3>Non-Contradiction Probability (<code class="docutils literal notranslate"><span class="pre">noncontradiction</span></code>)<a class="headerlink" href="#Non-Contradiction-Probability-(noncontradiction)" title="Link to this heading">#</a></h3>
<p>Non-contradiction probability (NCP) computes the mean non-contradiction probability estimated by a natural language inference (NLI) model. This score is formally defined as follows:</p>
<div class="math notranslate nohighlight">
\[NCP(y_i; \tilde{\mathbf{y}}_i) = 1 - \frac{1}{m} \sum_{j=1}^m\frac{p_{contra}(y_i, \tilde{y}_{ij}) + p_{contra}(y_i, \tilde{y}_{ij})}{2}.\]</div>
<p>Above, <span class="math notranslate nohighlight">\(p_{contra}(y_i, \tilde{y}_{ij})\)</span> denotes the (asymmetric) contradiction probability estimated by the NLI model for response <span class="math notranslate nohighlight">\(y_i\)</span> and candidate <span class="math notranslate nohighlight">\(\tilde{y}_{ij}\)</span>. For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>, <a class="reference external" href="https://arxiv.org/abs/2305.19187">Lin et al., 2024</a>, or <a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>.</p>
</section>
<section id="Entailment-Probability-(entailment)">
<h3>Entailment Probability (<code class="docutils literal notranslate"><span class="pre">entailment</span></code>)<a class="headerlink" href="#Entailment-Probability-(entailment)" title="Link to this heading">#</a></h3>
<p>Entailment probability (EP) computes the mean entailment probability estimated by a natural language inference (NLI) model. This score is formally defined as follows:</p>
<div class="math notranslate nohighlight">
\[EP(y_i; \tilde{\mathbf{y}}_i) = \frac{1}{m} \sum_{j=1}^m\frac{p_{entail}(y_i, \tilde{y}_{ij}) + p_{entail}(y_i, \tilde{y}_{ij})}{2}.\]</div>
<p>Above, <span class="math notranslate nohighlight">\(p_{entail}(y_i, \tilde{y}_{ij})\)</span> denotes the (asymmetric) entailment probability estimated by the NLI model for response <span class="math notranslate nohighlight">\(y_i\)</span> and candidate <span class="math notranslate nohighlight">\(\tilde{y}_{ij}\)</span>. We adapt this scorer from <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>, <a class="reference external" href="https://arxiv.org/abs/2305.19187">Lin et al., 2024</a>.</p>
</section>
<section id="Normalized-Semantic-Negentropy-(semantic_negentropy)">
<h3>Normalized Semantic Negentropy (<code class="docutils literal notranslate"><span class="pre">semantic_negentropy</span></code>)<a class="headerlink" href="#Normalized-Semantic-Negentropy-(semantic_negentropy)" title="Link to this heading">#</a></h3>
<p>Normalized Semantic Negentropy (NSN) normalizes the standard computation of discrete semantic entropy to be increasing with higher confidence and have [0,1] support. In contrast to the EMR and NCP, semantic entropy does not distinguish between an original response and candidate responses. Instead, this approach computes a single metric value on a list of responses generated from the same prompt. Under this approach, responses are clustered using an NLI model based on mutual entailment. We
consider the discrete version of SE, where the final set of clusters is defined as follows:</p>
<div class="math notranslate nohighlight">
\[SE(y_i; \tilde{\mathbf{y}}_i) = - \sum_{C \in \mathcal{C}} P(C|y_i, \tilde{\mathbf{y}}_i)\log P(C|y_i, \tilde{\mathbf{y}}_i),\]</div>
<p>where <span class="math notranslate nohighlight">\(P(C|y_i, \tilde{\mathbf{y}}_i)\)</span> is calculated as the probability a randomly selected response $y <span class="math">\in `{y_i} :nbsphinx-math:</span>cup <cite>:nbsphinx-math:</cite>tilde{mathbf{y}}`_i $ belongs to cluster <span class="math notranslate nohighlight">\(C\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> denotes the full set of clusters of <span class="math notranslate nohighlight">\(\{y_i\} \cup \tilde{\mathbf{y}}_i\)</span>.</p>
<p>To ensure that we have a normalized confidence score with <span class="math notranslate nohighlight">\([0,1]\)</span> support and with higher values corresponding to higher confidence, we implement the following normalization to arrive at <em>Normalized Semantic Negentropy</em> (NSN):</p>
<div class="math notranslate nohighlight">
\[NSN(y_i; \tilde{\mathbf{y}}_i) = 1 - \frac{SE(y_i; \tilde{\mathbf{y}}_i)}{\log m},\]</div>
<p>where <span class="math notranslate nohighlight">\(\log m\)</span> is included to normalize the support. For more on discrete semantic entropy, refer to <a class="reference external" href="https://www.nature.com/articles/s41586-024-07421-0">Farquhar et al., 2024</a>; <a class="reference external" href="https://arxiv.org/pdf/2302.09664">Kuhn et al., 2023</a>, and for more on our normalized version, refer to <a class="reference external" href="https://arxiv.org/abs/2504.19254">Bouchard &amp; Chauhan, 2025</a>.</p>
</section>
<section id="Number-of-Semantic-Sets-(semantic_sets_confidence)">
<h3>Number of Semantic Sets (<code class="docutils literal notranslate"><span class="pre">semantic_sets_confidence</span></code>)<a class="headerlink" href="#Number-of-Semantic-Sets-(semantic_sets_confidence)" title="Link to this heading">#</a></h3>
<p>Number of Semantic Sets counts the number of unique response sets (clusters) obtained during the computation of semantic entropy, as defined above. Let <span class="math notranslate nohighlight">\(N_C\)</span> denote the number of unique semantic clusters and <span class="math notranslate nohighlight">\(m\)</span> denote the number of sampled responses. We normalize this count to obtain a confidence score, Semantic Sets Confidence (SSC) in <span class="math notranslate nohighlight">\([0,1]\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[SSC(y_i; \tilde{\mathbf{y}}_i) =  \frac{m - N_C}{m - 1}.\]</div>
<p>Note that when <span class="math notranslate nohighlight">\(N_C=1\)</span>, all sampled responses are semantically equivalent, so the confidence score is 1, and when <span class="math notranslate nohighlight">\(N_C=m\)</span>, all responses are semantically distinct, so the confidence score is 0. For more on Number of Semantic Sets, refer to <a class="reference external" href="https://arxiv.org/abs/2305.19187">Lin et al., 2024</a>; <a class="reference external" href="https://arxiv.org/abs/2406.15627">Vashurin et al., 2025</a>; <a class="reference external" href="https://arxiv.org/pdf/2302.09664">Kuhn et al., 2023</a>.</p>
</section>
<section id="BERTScore-(bert_score)">
<h3>BERTScore (<code class="docutils literal notranslate"><span class="pre">bert_score</span></code>)<a class="headerlink" href="#BERTScore-(bert_score)" title="Link to this heading">#</a></h3>
<p>Let a tokenized text sequence be denoted as <span class="math notranslate nohighlight">\(\textbf{t} = \{t_1,...t_L\}\)</span> and the corresponding contextualized word embeddings as <span class="math notranslate nohighlight">\(\textbf{E} = \{\textbf{e}_1,...,\textbf{e}_L\}\)</span>, where <span class="math notranslate nohighlight">\(L\)</span> is the number of tokens in the text. The BERTScore precision, recall, and F1-scores between two tokenized texts <span class="math notranslate nohighlight">\(\textbf{t}, \textbf{t}'\)</span> are respectively defined as follows:</p>
<div class="math notranslate nohighlight">
\[BertP(\textbf{t}, \textbf{t}') = \frac{1}{| \textbf{t}|} \sum_{t \in \textbf{t}} \max_{t' \in \textbf{t}'} \textbf{e} \cdot \textbf{e}'\]</div>
<div class="math notranslate nohighlight">
\[BertR(\textbf{t}, \textbf{t}') = \frac{1}{| \textbf{t}'|} \sum_{t' \in \textbf{t}'} \max_{t \in \textbf{t}} \textbf{e} \cdot \textbf{e}'\]</div>
<div class="math notranslate nohighlight">
\[BertF(\textbf{t}, \textbf{t}') = 2\frac{ BertP(\textbf{t}, \textbf{t}')  BertR(\textbf{t}, \textbf{t}')}{BertP(\textbf{t}, \textbf{t}')  + BertRec(\textbf{t}, \textbf{t}')},\]</div>
<p>where <span class="math notranslate nohighlight">\(e, e'\)</span> respectively correspond to <span class="math notranslate nohighlight">\(t, t'\)</span>. We compute our BERTScore-based confidence scores as follows:</p>
<div class="math notranslate nohighlight">
\[BertConf(y_i; \tilde{\mathbf{y}}_i) = \frac{1}{m} \sum_{j=1}^m BertF(y_i, \tilde{y}_{ij}),\]</div>
<p>i.e. the average BERTScore F1 across pairings of the original response with all candidate responses. For more on BERTScore, refer to <a class="reference external" href="https://arxiv.org/abs/1904.09675">Zheng et al., 2020</a>.</p>
</section>
<section id="Normalized-Cosine-Similarity-(cosine_sim)">
<h3>Normalized Cosine Similarity (<code class="docutils literal notranslate"><span class="pre">cosine_sim</span></code>)<a class="headerlink" href="#Normalized-Cosine-Similarity-(cosine_sim)" title="Link to this heading">#</a></h3>
<p>This scorer leverages a sentence transformer to map LLM outputs to an embedding space and measure similarity using those sentence embeddings. Let <span class="math notranslate nohighlight">\(V: \mathcal{Y} \xrightarrow{} \mathbb{R}^d\)</span> denote the sentence transformer, where <span class="math notranslate nohighlight">\(d\)</span> is the dimension of the embedding space. The average cosine similarity across pairings of the original response with all candidate responses is given as follows:</p>
<div class="math notranslate nohighlight">
\[CS(y_i; \tilde{\mathbf{y}}_i) = \frac{1}{m} \sum_{i=1}^m   \frac{\mathbf{V}(y_i) \cdot \mathbf{V}(\tilde{y}_{ij}) }{ \lVert \mathbf{V}(y_i) \rVert \lVert \mathbf{V}(\tilde{y}_{ij}) \rVert}.\]</div>
<p>To ensure a standardized support of <span class="math notranslate nohighlight">\([0, 1]\)</span>, we normalize cosine similarity to obtain confidence scores as follows:</p>
<div class="math notranslate nohighlight">
\[NCS(y_i; \tilde{\mathbf{y}}_i) = \frac{CS(y_i; \tilde{\mathbf{y}}_i) + 1}{2}.\]</div>
<p>¬© 2025 CVS Health and/or one of its affiliates. All rights reserved.</p>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="white_box_single_generation_demo.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">üéØ White-Box Uncertainty Quantification</p>
      </div>
    </a>
    <a class="right-next"
       href="multimodal_demo.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">üéØ Multimodal Uncertainty Quantification</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#üìä-What-You'll-Do-in-This-Demo">üìä What You‚Äôll Do in This Demo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#‚öñÔ∏è-Advantages-&amp;-Limitations">‚öñÔ∏è Advantages &amp; Limitations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#1.-Set-up-LLM-and-Prompts">1. Set up LLM and Prompts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#2.-Generate-LLM-Responses-and-Confidence-Scores">2. Generate LLM Responses and Confidence Scores</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#BlackBoxUQ()---Generate-LLM-responses-and-compute-consistency-based-confidence-scores-for-each-response."><code class="docutils literal notranslate"><span class="pre">BlackBoxUQ()</span></code> - Generate LLM responses and compute consistency-based confidence scores for each response.</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#üìã-Class-Attributes">üìã Class Attributes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#üîç-Parameter-Groups">üîç Parameter Groups</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#üíª-Usage-Examples">üíª Usage Examples</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#üîÑ-Class-Methods">üîÑ Class Methods</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#3.-Evaluate-Hallucination-Detection-Performance">3. Evaluate Hallucination Detection Performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#4.-Scorer-Definitions">4. Scorer Definitions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Exact-Match-Rate-(exact_match)">Exact Match Rate (<code class="docutils literal notranslate"><span class="pre">exact_match</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Non-Contradiction-Probability-(noncontradiction)">Non-Contradiction Probability (<code class="docutils literal notranslate"><span class="pre">noncontradiction</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Entailment-Probability-(entailment)">Entailment Probability (<code class="docutils literal notranslate"><span class="pre">entailment</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Normalized-Semantic-Negentropy-(semantic_negentropy)">Normalized Semantic Negentropy (<code class="docutils literal notranslate"><span class="pre">semantic_negentropy</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Number-of-Semantic-Sets-(semantic_sets_confidence)">Number of Semantic Sets (<code class="docutils literal notranslate"><span class="pre">semantic_sets_confidence</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#BERTScore-(bert_score)">BERTScore (<code class="docutils literal notranslate"><span class="pre">bert_score</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Normalized-Cosine-Similarity-(cosine_sim)">Normalized Cosine Similarity (<code class="docutils literal notranslate"><span class="pre">cosine_sim</span></code>)</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/_notebooks/examples/black_box_demo.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2025, CVS Health.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>