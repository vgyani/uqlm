
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" sizes="16x16" href="../../_static/images/favicon/favicon-16x16.png" type="image/png">
    <link rel="icon" sizes="32x32" href="../../_static/images/favicon/favicon-32x32.png" type="image/png">
    <link rel="apple-touch-icon" sizes="180x180" href="../../_static/images/favicon/apple-touch-icon.png" type="image/png">
    <title>üéØ White-Box Uncertainty Quantification &#8212; uqlm 0.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=662d8ef6" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=10f1778b"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "displayMath": [["$$", "$$"], ["\\[", "\\]"]]}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_notebooks/examples/white_box_multi_generation_demo';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://cvs-health.github.io/uqlm/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.2';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="üéØ White-Box Uncertainty Quantification" href="white_box_single_generation_demo.html" />
    <link rel="prev" title="üéØ Semantic Density" href="semantic_density_demo.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/horizontal_logo.png" class="logo__image only-light" alt="uqlm 0.2 documentation - Home"/>
    <img src="../../_static/horizontal_logo_no_bg.png" class="logo__image only-dark pst-js-only" alt="uqlm 0.2 documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../scorer_definitions/index.html">
    Scorer Definitions
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../scorer_definitions/index.html">
    Scorer Definitions
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ensemble_off_the_shelf_demo.html">üéØ BS Detector: Off-the-Shelf Ensemble for LLM Uncertainty</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensemble_tuning_demo.html">üéØ Tunable Ensemble for LLM Uncertainty (Advanced)</a></li>
<li class="toctree-l1"><a class="reference internal" href="judges_demo.html">üéØ LLM-as-a-Judge</a></li>
<li class="toctree-l1"><a class="reference internal" href="semantic_entropy_demo.html">üéØ Semantic Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="semantic_density_demo.html">üéØ Semantic Density</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">üéØ White-Box Uncertainty Quantification</a></li>
<li class="toctree-l1"><a class="reference internal" href="white_box_single_generation_demo.html">üéØ White-Box Uncertainty Quantification</a></li>
<li class="toctree-l1"><a class="reference internal" href="black_box_demo.html">üéØ Black-Box Uncertainty Quantification</a></li>
<li class="toctree-l1"><a class="reference internal" href="multimodal_demo.html">üéØ Multimodal Uncertainty Quantification</a></li>
<li class="toctree-l1"><a class="reference internal" href="score_calibration_demo.html">üéØ Confidence Score Calibration Demo</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Example Notebooks</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">üéØ White-Box Uncertainty Quantification</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="üéØ-White-Box-Uncertainty-Quantification">
<h1>üéØ White-Box Uncertainty Quantification<a class="headerlink" href="#üéØ-White-Box-Uncertainty-Quantification" title="Link to this heading">#</a></h1>
<div style="background-color: rgba(200, 200, 200, 0.1); padding: 20px; border-radius: 8px; margin-bottom: 20px; border: 1px solid rgba(127, 127, 127, 0.2); max-width: 97.5%; overflow-wrap: break-word;"><p style="font-size: 16px; line-height: 1.6"><p>White-box Uncertainty Quantification (UQ) methods leverage token probabilities to estimate uncertainty. Multi-generation white-box methods generate multiple responses from the same prompt, combining the sampling approach of black-box UQ with token-probability-based singals. This demo provides an illustration of how to use state-of-the-art white-box UQ methods with uqlm. The following multi-generation scorers are available:</p>
</p><ul class="simple">
<li><p>Monte carlo sequence probability (<a class="reference external" href="https://arxiv.org/abs/2302.09664">Kuhn et al., 2023</a>)</p></li>
<li><p>Consistency and Confidence (CoCoA) (<a class="reference external" href="https://arxiv.org/abs/2502.04964">Vashurin et al., 2025</a>)</p></li>
<li><p>Semantic Negentropy (<a class="reference external" href="https://www.nature.com/articles/s41586-024-07421-0">Farquhar et al., 2024</a>)</p></li>
<li><p>Semantic Density (<a class="reference external" href="https://arxiv.org/abs/2405.13845">Qiu et al., 2024</a>)</p></li>
<li><p>P(True) (<a class="reference external" href="https://arxiv.org/abs/2207.05221">Kadavath et al., 2022</a>)</p></li>
</ul>
</div><section id="üìä-What-You'll-Do-in-This-Demo">
<h2>üìä What You‚Äôll Do in This Demo<a class="headerlink" href="#üìä-What-You'll-Do-in-This-Demo" title="Link to this heading">#</a></h2>
<div style="display: flex; margin-bottom: 15px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>1</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Set up LLM and prompts.</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Set up LLM instance and load example data prompts.</p>
</p></div></div><div style="display: flex; margin-bottom: 15px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>2</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Generate LLM Responses and Confidence Scores</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Generate and score LLM responses to the example questions using the WhiteBoxUQ() class.</p>
</p></div></div><div style="display: flex; margin-bottom: 25px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>3</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Evaluate Hallucination Detection Performance</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Visualize model accuracy at different thresholds of the various white-box UQ confidence scores. Compute precision, recall, and F1-score of hallucination detection.</p>
</p></div></div></section>
<section id="‚öñÔ∏è-Advantages-&amp;-Limitations">
<h2>‚öñÔ∏è Advantages &amp; Limitations<a class="headerlink" href="#‚öñÔ∏è-Advantages-&-Limitations" title="Link to this heading">#</a></h2>
<div style="display: flex; gap: 20px"><div style="flex: 1; background-color: rgba(0, 200, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(0, 200, 0, 0.2)"><h3 style="color: #2e8b57; margin-top: 0"><p>Pros</p>
</h3><ul style="margin-bottom: 0"><li><p>Robust Uncertainty Signals: Leverages token probabilities from multiple sampled responses.</p>
</li><li><p>SOTA Performance: Enables use of top SOTA methods, including Semantic Entropy and Semantic Density.</p>
</li></ul></div><div style="flex: 1; background-color: rgba(200, 0, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(200, 0, 0, 0.2)"><h3 style="color: #b22222; margin-top: 0"><p>Cons</p>
</h3><ul style="margin-bottom: 0"><li><p>Limited Compatibility: Requires access to token probabilities, not available for all LLMs/APIs.</p>
</li><li><p>Higher Cost: Requires multiple generations per prompt</p>
</li><li><p>Slower: Multiple generations and comparison calculations increase latency</p>
</li></ul></div></div><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm</span><span class="w"> </span><span class="kn">import</span> <span class="n">WhiteBoxUQ</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_example_dataset</span><span class="p">,</span> <span class="n">math_postprocessor</span><span class="p">,</span> <span class="n">plot_model_accuracies</span><span class="p">,</span> <span class="n">Tuner</span>
</pre></div>
</div>
</div>
<p>## 1. Set up LLM and Prompts</p>
<p>In this demo, we will illustrate this approach using a set of math questions from the <a class="reference external" href="https://github.com/openai/grade-school-math">gsm8k benchmark</a>. To implement with your use case, simply <strong>replace the example prompts with your data</strong>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load example dataset (gsm8k)</span>
<span class="n">gsm8k</span> <span class="o">=</span> <span class="n">load_example_dataset</span><span class="p">(</span><span class="s2">&quot;gsm8k&quot;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">gsm8k</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading dataset - gsm8k...
Processing dataset...
Dataset ready!
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>question</th>
      <th>answer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Natalia sold clips to 48 of her friends in Apr...</td>
      <td>72</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Weng earns $12 an hour for babysitting. Yester...</td>
      <td>10</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Betty is saving money for a new wallet which c...</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Julie is reading a 120-page book. Yesterday, s...</td>
      <td>42</td>
    </tr>
    <tr>
      <th>4</th>
      <td>James writes a 3-page letter to 2 different fr...</td>
      <td>624</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define prompts</span>
<span class="n">MATH_INSTRUCTION</span> <span class="o">=</span> <span class="s2">&quot;When you solve this math problem only return the answer with no additional text.</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">MATH_INSTRUCTION</span> <span class="o">+</span> <span class="n">prompt</span> <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">gsm8k</span><span class="o">.</span><span class="n">question</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>In this example, we use <code class="docutils literal notranslate"><span class="pre">AzureChatOpenAI</span></code> to instantiate our LLM, but any <a class="reference external" href="https://js.langchain.com/docs/integrations/chat/">LangChain Chat Model</a> may be used. Be sure to <strong>replace with your LLM of choice.</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import sys</span>
<span class="c1"># !{sys.executable} -m pip install python-dotenv</span>
<span class="c1"># !{sys.executable} -m pip install langchain-openai</span>

<span class="c1"># # User to populate .env file with API credentials. In this step, replace with your LLM of choice.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span><span class="p">,</span> <span class="n">find_dotenv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">AzureChatOpenAI</span>

<span class="n">load_dotenv</span><span class="p">(</span><span class="n">find_dotenv</span><span class="p">())</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">AzureChatOpenAI</span><span class="p">(</span><span class="n">deployment_name</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">,</span> <span class="n">openai_api_type</span><span class="o">=</span><span class="s2">&quot;azure&quot;</span><span class="p">,</span> <span class="n">openai_api_version</span><span class="o">=</span><span class="s2">&quot;2024-02-15-preview&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>## 2. Generate responses and confidence scores</p>
<section id="WhiteBoxUQ()---Generate-LLM-responses-and-compute-token-probability-based-confidence-scores-for-each-response.">
<h3><code class="docutils literal notranslate"><span class="pre">WhiteBoxUQ()</span></code> - Generate LLM responses and compute token-probability-based confidence scores for each response.<a class="headerlink" href="#WhiteBoxUQ()---Generate-LLM-responses-and-compute-token-probability-based-confidence-scores-for-each-response." title="Link to this heading">#</a></h3>
<p><img alt="Sample Image" src="https://raw.githubusercontent.com/cvs-health/uqlm/develop/assets/images/white_box_graphic.png" /></p>
<section id="üìã-Class-Attributes">
<h4>üìã Class Attributes<a class="headerlink" href="#üìã-Class-Attributes" title="Link to this heading">#</a></h4>
<table style="border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);"><tr><th style="background-color: rgba(200, 200, 200, 0.2); width: 20%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Parameter</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Type &amp; Default</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 55%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Description</p>
</th></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>llm</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BaseChatModeldefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>A langchain llm <code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code>. User is responsible for specifying temperature and other relevant parameters to the constructor of their <code class="docutils literal notranslate"><span class="pre">llm</span></code> object.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>scorers</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>List[str]default=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies which white-box UQ scorers to include. Must be subset of [‚Äúnormalized_probability‚Äù, ‚Äúmin_probability‚Äù, ‚Äúsequence_probability‚Äù, ‚Äúmax_token_negentropy‚Äù, ‚Äúmean_token_negentropy‚Äù, ‚Äúprobability_margin‚Äù, ‚Äúmonte_carlo_negentropy‚Äù, ‚Äúconsistency_and_confidence‚Äù, ‚Äúsemantic_negentropy‚Äù, ‚Äúsemantic_density‚Äù, ‚Äúp_true‚Äù]. If None, defaults to [‚Äúnormalized_probability‚Äù, ‚Äúmin_probability‚Äù].</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>system_prompt</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>str or Nonedefault=‚ÄùYou are a helpful assistant.‚Äù</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Optional argument for user to provide custom system prompt for the LLM.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>max_calls_per_min</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>intdefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies how many API calls to make per minute to avoid rate limit errors. By default, no limit is specified.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>sampling_temperature</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>floatdefault=1</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>The ‚Äòtemperature‚Äô parameter for LLM to use when generating sampled LLM responses. Only applies to ‚Äúmonte_carlo_negentropy‚Äù, ‚Äúconsistency_and_confidence‚Äù, ‚Äúsemantic_negentropy‚Äù, ‚Äúsemantic_density‚Äù. Must be greater than 0.</p>
</td></tr></table></section>
<section id="üîç-Parameter-Groups">
<h4>üîç Parameter Groups<a class="headerlink" href="#üîç-Parameter-Groups" title="Link to this heading">#</a></h4>
<div style="display: flex; gap: 20px; margin-bottom: 20px"><div style="flex: 1; padding: 10px; background-color: rgba(0, 100, 200, 0.1); border-radius: 5px; border: 1px solid rgba(0, 100, 200, 0.2);"><p style="font-weight: bold"><p>üß† Model-Specific</p>
</p><ul><li><p>llm</p>
</li><li><p>system_prompt</p>
</li><li><p>sampling_temperature</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(0, 200, 0, 0.1); border-radius: 5px; border: 1px solid rgba(0, 200, 0, 0.2);"><p style="font-weight: bold"><p>üìä Confidence Scores</p>
</p><ul><li><p>scorers</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(200, 0, 200, 0.1); border-radius: 5px; border: 1px solid rgba(200, 0, 200, 0.2);"><p style="font-weight: bold"><p>‚ö° Performance</p>
</p><ul><li><p>max_calls_per_min</p>
</li></ul></div></div><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wbuq</span> <span class="o">=</span> <span class="n">WhiteBoxUQ</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;monte_carlo_probability&quot;</span><span class="p">,</span>  <span class="c1"># requires multiple sampled responses per prompt</span>
        <span class="s2">&quot;consistency_and_confidence&quot;</span><span class="p">,</span>  <span class="c1"># requires multiple sampled responses per prompt</span>
        <span class="s2">&quot;p_true&quot;</span><span class="p">,</span>  <span class="c1"># generates one additional response per prompt, acts as logprobs-based self-judge</span>
    <span class="p">],</span>
    <span class="n">max_calls_per_min</span><span class="o">=</span><span class="mi">125</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="üîÑ-Class-Methods">
<h3>üîÑ Class Methods<a class="headerlink" href="#üîÑ-Class-Methods" title="Link to this heading">#</a></h3>
<table style="border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);"><tr><th style="background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Method</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 75%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Description &amp; Parameters</p>
</th></tr><tr><td style="font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>WhiteBoxUQ.generate_and_score</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p><p>Generate LLM responses and compute confidence scores for the provided prompts.</p>
</p><p><p>Parameters:</p>
</p><ul><li><p>prompts - (List[str] or List[List[BaseMessage]]) A list of input prompts for the model.</p>
</li><li><p>num_responses - (int, default=5) The number of sampled responses to generate for sampling-based white-box UQ methods. Only applies to ‚Äúmonte_carlo_negentropy‚Äù, ‚Äúconsistency_and_confidence‚Äù, ‚Äúsemantic_negentropy‚Äù, ‚Äúsemantic_density‚Äù.</p>
</li><li><p>show_progress_bars - (bool, default=True) If True, displays a progress bar while generating and scoring responses.</p>
</li></ul><p><p>Returns: UQResult containing data (prompts, responses, log probabilities, and confidence scores) and metadata</p>
</p><div style="background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;"><p>üí° Best For: Complete end-to-end uncertainty quantification when starting with prompts.</p>
</div></td></tr><tr><td style="font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BlackBoxUQ.score</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p><p>Compute confidence scores on provided LLM responses and logprobs. Should only be used if responses and sampled responses are already generated with logprobs.</p>
</p><p><p>Parameters:</p>
</p><ul><li><p>responses - (List[str]) A list of LLM responses for the prompts.</p>
</li><li><p>logprob_results - (List[List[str]]) A list of dictionaries, each returned by BaseChatModel.agenerate corresponding to responses.</p>
</li><li><p>sampled_responses - (List[List[str]], default=None) A list of lists of sampled LLM responses for each prompt. Used to compute consistency scores by comparing to the corresponding response from responses. Required only for ‚Äúmonte_carlo_negentropy‚Äù, ‚Äúconsistency_and_confidence‚Äù, ‚Äúsemantic_negentropy‚Äù, ‚Äúsemantic_density‚Äù scorers.</p>
</li><li><p>sampled_logprob_results - (List[List[str]], default=None) List of list of dictionaries, each returned by BaseChatModel.agenerate. These must correspond to sampled_responses. Required only for ‚Äúmonte_carlo_negentropy‚Äù, ‚Äúconsistency_and_confidence‚Äù, ‚Äúsemantic_negentropy‚Äù, ‚Äúsemantic_density‚Äù scorers.</p>
</li><li><p>prompts - (List[List[str]], default=None) List of prompts from which responses were generated. Required only for ‚Äúp_true‚Äù scorer.</p>
</li><li><p>show_progress_bars - (bool, default=True) If True, displays a progress bar while scoring responses.</p>
</li></ul><p><p>Returns: UQResult containing data (responses, sampled responses, and confidence scores) and metadata</p>
</p><div style="background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;"><p>üí° Best For: Computing uncertainty scores when responses and logprobs are already generated elsewhere.</p>
</div></td></tr></table><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">wbuq</span><span class="o">.</span><span class="n">generate_and_score</span><span class="p">(</span><span class="n">prompts</span><span class="o">=</span><span class="n">prompts</span><span class="p">,</span> <span class="n">num_responses</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ab71f72963e74b979bd369a1b508c123", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result_df</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prompt</th>
      <th>response</th>
      <th>logprob</th>
      <th>sampled_responses</th>
      <th>sampled_logprob</th>
      <th>consistency_and_confidence</th>
      <th>monte_carlo_probability</th>
      <th>p_true</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>When you solve this math problem only return t...</td>
      <td>72</td>
      <td>[{'token': '72', 'bytes': [55, 50], 'logprob':...</td>
      <td>[72, 72, 72, 72, 72]</td>
      <td>[[{'token': '72', 'bytes': [55, 50], 'logprob'...</td>
      <td>0.999819</td>
      <td>0.999955</td>
      <td>0.377549</td>
    </tr>
    <tr>
      <th>1</th>
      <td>When you solve this math problem only return t...</td>
      <td>$10</td>
      <td>[{'token': '$', 'bytes': [36], 'logprob': -0.0...</td>
      <td>[$10, $10, $10, $10, $10]</td>
      <td>[[{'token': '$', 'bytes': [36], 'logprob': -0....</td>
      <td>0.994463</td>
      <td>0.994415</td>
      <td>0.047430</td>
    </tr>
    <tr>
      <th>2</th>
      <td>When you solve this math problem only return t...</td>
      <td>$20</td>
      <td>[{'token': '$', 'bytes': [36], 'logprob': -0.0...</td>
      <td>[$20, $20, $20, $20, $10]</td>
      <td>[[{'token': '$', 'bytes': [36], 'logprob': -0....</td>
      <td>0.923075</td>
      <td>0.890358</td>
      <td>0.777260</td>
    </tr>
    <tr>
      <th>3</th>
      <td>When you solve this math problem only return t...</td>
      <td>48</td>
      <td>[{'token': '48', 'bytes': [52, 56], 'logprob':...</td>
      <td>[48, 48, 48, 48, 48]</td>
      <td>[[{'token': '48', 'bytes': [52, 56], 'logprob'...</td>
      <td>0.994755</td>
      <td>0.996196</td>
      <td>0.182436</td>
    </tr>
    <tr>
      <th>4</th>
      <td>When you solve this math problem only return t...</td>
      <td>624</td>
      <td>[{'token': '624', 'bytes': [54, 50, 52], 'logp...</td>
      <td>[624, 624 pages., 624, 624, 624]</td>
      <td>[[{'token': '624', 'bytes': [54, 50, 52], 'log...</td>
      <td>0.954816</td>
      <td>0.923305</td>
      <td>0.981987</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>## 3. Evaluate Hallucination Detection Performance</p>
<p>To evaluate hallucination detection performance, we ‚Äògrade‚Äô the responses against an answer key. Note the <code class="docutils literal notranslate"><span class="pre">math_postprocessor</span></code> is specific to our use case (math questions). <strong>If you are using your own prompts/questions, update the grading method accordingly</strong>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Populate correct answers</span>
<span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gsm8k</span><span class="o">.</span><span class="n">answer</span>

<span class="c1"># Grade responses against correct answers</span>
<span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;response_correct&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">math_postprocessor</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">==</span> <span class="n">a</span> <span class="k">for</span> <span class="n">r</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">],</span> <span class="n">gsm8k</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prompt</th>
      <th>response</th>
      <th>logprob</th>
      <th>sampled_responses</th>
      <th>sampled_logprob</th>
      <th>consistency_and_confidence</th>
      <th>monte_carlo_probability</th>
      <th>p_true</th>
      <th>answer</th>
      <th>response_correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>When you solve this math problem only return t...</td>
      <td>72</td>
      <td>[{'token': '72', 'bytes': [55, 50], 'logprob':...</td>
      <td>[72, 72, 72, 72, 72]</td>
      <td>[[{'token': '72', 'bytes': [55, 50], 'logprob'...</td>
      <td>0.999819</td>
      <td>0.999955</td>
      <td>0.377549</td>
      <td>72</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>When you solve this math problem only return t...</td>
      <td>$10</td>
      <td>[{'token': '$', 'bytes': [36], 'logprob': -0.0...</td>
      <td>[$10, $10, $10, $10, $10]</td>
      <td>[[{'token': '$', 'bytes': [36], 'logprob': -0....</td>
      <td>0.994463</td>
      <td>0.994415</td>
      <td>0.047430</td>
      <td>10</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>When you solve this math problem only return t...</td>
      <td>$20</td>
      <td>[{'token': '$', 'bytes': [36], 'logprob': -0.0...</td>
      <td>[$20, $20, $20, $20, $10]</td>
      <td>[[{'token': '$', 'bytes': [36], 'logprob': -0....</td>
      <td>0.923075</td>
      <td>0.890358</td>
      <td>0.777260</td>
      <td>5</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>When you solve this math problem only return t...</td>
      <td>48</td>
      <td>[{'token': '48', 'bytes': [52, 56], 'logprob':...</td>
      <td>[48, 48, 48, 48, 48]</td>
      <td>[[{'token': '48', 'bytes': [52, 56], 'logprob'...</td>
      <td>0.994755</td>
      <td>0.996196</td>
      <td>0.182436</td>
      <td>42</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>When you solve this math problem only return t...</td>
      <td>624</td>
      <td>[{'token': '624', 'bytes': [54, 50, 52], 'logp...</td>
      <td>[624, 624 pages., 624, 624, 624]</td>
      <td>[[{'token': '624', 'bytes': [54, 50, 52], 'log...</td>
      <td>0.954816</td>
      <td>0.923305</td>
      <td>0.981987</td>
      <td>624</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;Baseline LLM accuracy: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;response_correct&quot;</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Baseline LLM accuracy: 0.53
</pre></div></div>
</div>
<section id="3.1-Filtered-LLM-Accuracy-Evaluation">
<h4>3.1 Filtered LLM Accuracy Evaluation<a class="headerlink" href="#3.1-Filtered-LLM-Accuracy-Evaluation" title="Link to this heading">#</a></h4>
<p>Here, we explore ‚Äòfiltered accuracy‚Äô as a metric for evaluating the performance of our confidence scores. Filtered accuracy measures the change in LLM performance when responses with confidence scores below a specified threshold are excluded. By adjusting the confidence score threshold, we can observe how the accuracy of the LLM improves as less certain responses are filtered out.</p>
<p>We will plot the filtered accuracy across various confidence score thresholds to visualize the relationship between confidence and LLM accuracy. This analysis helps in understanding the trade-off between response coverage (measured by sample size below) and LLM accuracy, providing insights into the reliability of the LLM‚Äôs outputs. We conduct this analysis separately for each of our scorers.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">scorer</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;monte_carlo_probability&quot;</span><span class="p">,</span> <span class="s2">&quot;consistency_and_confidence&quot;</span><span class="p">,</span> <span class="s2">&quot;p_true&quot;</span><span class="p">]:</span>
    <span class="n">plot_model_accuracies</span><span class="p">(</span><span class="n">scores</span><span class="o">=</span><span class="n">result_df</span><span class="p">[</span><span class="n">scorer</span><span class="p">],</span> <span class="n">correct_indicators</span><span class="o">=</span><span class="n">result_df</span><span class="o">.</span><span class="n">response_correct</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;LLM Accuracy by </span><span class="si">{</span><span class="n">scorer</span><span class="si">}</span><span class="s2"> Score Threshold&quot;</span><span class="p">,</span> <span class="n">display_percentage</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_white_box_multi_generation_demo_20_0.png" src="../../_images/_notebooks_examples_white_box_multi_generation_demo_20_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_white_box_multi_generation_demo_20_1.png" src="../../_images/_notebooks_examples_white_box_multi_generation_demo_20_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_white_box_multi_generation_demo_20_2.png" src="../../_images/_notebooks_examples_white_box_multi_generation_demo_20_2.png" />
</div>
</div>
</section>
<section id="3.2-Precision,-Recall,-F1-Score-of-Hallucination-Detection">
<h4>3.2 Precision, Recall, F1-Score of Hallucination Detection<a class="headerlink" href="#3.2-Precision,-Recall,-F1-Score-of-Hallucination-Detection" title="Link to this heading">#</a></h4>
<p>Lastly, we compute the optimal threshold for binarizing confidence scores, using F1-score as the objective. Using this threshold, we compute precision, recall, and F1-score for black box scorer predictions of whether responses are correct.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate UQLM tuner object for threshold selection</span>
<span class="n">split</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">Tuner</span><span class="p">()</span>

<span class="n">correct_indicators</span> <span class="o">=</span> <span class="p">(</span><span class="n">result_df</span><span class="o">.</span><span class="n">response_correct</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span>  <span class="c1"># Whether responses is actually correct</span>
<span class="n">metric_values</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Precision&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;Recall&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;F1-score&quot;</span><span class="p">:</span> <span class="p">[]}</span>
<span class="n">optimal_thresholds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">confidence_score</span> <span class="ow">in</span> <span class="n">wbuq</span><span class="o">.</span><span class="n">scorers</span><span class="p">:</span>
    <span class="c1"># tune threshold on first half</span>
    <span class="n">y_scores</span> <span class="o">=</span> <span class="n">result_df</span><span class="p">[</span><span class="n">confidence_score</span><span class="p">]</span>
    <span class="n">y_scores_tune</span> <span class="o">=</span> <span class="n">y_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">split</span><span class="p">]</span>
    <span class="n">y_true_tune</span> <span class="o">=</span> <span class="n">correct_indicators</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">split</span><span class="p">]</span>
    <span class="n">best_threshold</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">tune_threshold</span><span class="p">(</span><span class="n">y_scores</span><span class="o">=</span><span class="n">y_scores_tune</span><span class="p">,</span> <span class="n">correct_indicators</span><span class="o">=</span><span class="n">y_true_tune</span><span class="p">,</span> <span class="n">thresh_objective</span><span class="o">=</span><span class="s2">&quot;fbeta_score&quot;</span><span class="p">)</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[(</span><span class="n">s</span> <span class="o">&gt;</span> <span class="n">best_threshold</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">y_scores</span><span class="p">]</span>  <span class="c1"># predicts whether response is correct based on confidence score</span>
    <span class="n">optimal_thresholds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_threshold</span><span class="p">)</span>

    <span class="c1"># evaluate on last half</span>
    <span class="n">y_true_eval</span> <span class="o">=</span> <span class="n">correct_indicators</span><span class="p">[</span><span class="n">split</span><span class="p">:]</span>
    <span class="n">y_pred_eval</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">split</span><span class="p">:]</span>
    <span class="n">metric_values</span><span class="p">[</span><span class="s2">&quot;Precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true_eval</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred_eval</span><span class="p">))</span>
    <span class="n">metric_values</span><span class="p">[</span><span class="s2">&quot;Recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true_eval</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred_eval</span><span class="p">))</span>
    <span class="n">metric_values</span><span class="p">[</span><span class="s2">&quot;F1-score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true_eval</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred_eval</span><span class="p">))</span>

<span class="c1"># print results</span>
<span class="n">header</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Metrics&#39;</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scorer_name</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">scorer_name</span> <span class="ow">in</span> <span class="n">wbuq</span><span class="o">.</span><span class="n">scorers</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">header</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">header</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">header</span><span class="p">))</span>
<span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metric_values</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">metric_values</span><span class="p">[</span><span class="n">metric</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">header</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;F-1 optimal threshold&#39;</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">optimal_thresholds</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">header</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
========================================================================================================================
Metrics                       monte_carlo_probability       consistency_and_confidence    p_true
------------------------------------------------------------------------------------------------------------------------
Precision                     0.885                         0.909                         0.522
Recall                        0.885                         0.769                         0.923
F1-score                      0.885                         0.833                         0.667
------------------------------------------------------------------------------------------------------------------------
F-1 optimal threshold         0.64                          0.74                          0.02
========================================================================================================================
</pre></div></div>
</div>
<p>## 4. Scorer Definitions White-box UQ scorers leverage token probabilities of the LLM‚Äôs generated response to quantify uncertainty. All scorers have outputs ranging from 0 to 1, with higher values indicating higher confidence. We define several multi-generation white-box UQ scorers below.</p>
<p>Let the tokenization LLM response <span class="math notranslate nohighlight">\(y_i\)</span> be denoted as <span class="math notranslate nohighlight">\(\{t_1,...,t_{L_i}\}\)</span>, where <span class="math notranslate nohighlight">\(L_i\)</span> denotes the number of tokens the response. Further, let <span class="math notranslate nohighlight">\(y_1,...,y_m\)</span> denote <span class="math notranslate nohighlight">\(m\)</span> sampled responses generated from the same prompt.</p>
</section>
</section>
<section id="Monte-Carlo-Sequence-Probability-(monte_carlo_probability)">
<h3>Monte Carlo Sequence Probability (<code class="docutils literal notranslate"><span class="pre">monte_carlo_probability</span></code>)<a class="headerlink" href="#Monte-Carlo-Sequence-Probability-(monte_carlo_probability)" title="Link to this heading">#</a></h3>
<p>Monte Carlo Sequence Probability (MCSP) computes the average length-normalized sequence probability across sampled responses.</p>
<div class="math notranslate nohighlight">
\[MCSP(y_1,y_2,...,y_m) =  \frac{1}{m} \sum_{i=1}^m  \prod_{t \in y_i}  p_t^{\frac{1}{L_i}}\]</div>
<p>For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2302.09664">Kuhn et al., 2023</a>.</p>
</section>
<section id="Consistency-and-Confidence-Approach-(CoCoA)-(consistency_and_confidence)">
<h3>Consistency and Confidence Approach (CoCoA) (<code class="docutils literal notranslate"><span class="pre">consistency_and_confidence</span></code>)<a class="headerlink" href="#Consistency-and-Confidence-Approach-(CoCoA)-(consistency_and_confidence)" title="Link to this heading">#</a></h3>
<p>Consistency and Confidence Approach (CoCoA) leverages two distinct signals: 1) similarity between an original response <span class="math notranslate nohighlight">\(y_0\)</span> and a set of sampled responses <span class="math notranslate nohighlight">\(y_1,...,y_m\)</span> and token probabilities from the original response <span class="math notranslate nohighlight">\(y_0\)</span>.</p>
<p>We first get the length-normalized token probability of our original response:</p>
<div class="math notranslate nohighlight">
\[LNTP(y_0) = \prod_{t \in y_0}  p_t^{\frac{1}{L_0}}.\]</div>
<p>We then obtain average cosine similarity across pairings of the original response with all sampled responses, normalized to a [0,1] scale:</p>
<div class="math notranslate nohighlight">
\[NCS(y_0; y_1,...,y_m) = \frac{1}{m} \sum_{i=1}^m \frac{\cos(y_0; y_i) + 1}{2}.\]</div>
<p>CoCoa is then calculated as the product of these two terms.</p>
<div class="math notranslate nohighlight">
\[CoCoA(y_0; y_1,...,y_m) = LNTP(y_0) * NCS(y_0; y_1,...,y_m).\]</div>
<p>For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2502.04964">Vashurin et al., 2025</a>.</p>
</section>
<section id="Normalized-Semantic-Negentropy">
<h3>Normalized Semantic Negentropy<a class="headerlink" href="#Normalized-Semantic-Negentropy" title="Link to this heading">#</a></h3>
<p>Normalized Semantic Negentropy (NSN) normalizes the standard computation of discrete semantic entropy to be increasing with higher confidence and have [0,1] support. Under this approach, responses are clustered using an NLI model based on mutual entailment. After obtaining the set of clusters <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>, semantic entropy is computed as:</p>
<div class="math notranslate nohighlight">
\[SE(y_i; \tilde{\mathbf{y}}_i) = - \sum_{C \in \mathcal{C}} P(C|y_i, \tilde{\mathbf{y}}_i)\log P(C|y_i, \tilde{\mathbf{y}}_i),\]</div>
<p>where <span class="math notranslate nohighlight">\(P(C|y_i, \tilde{\mathbf{y}}_i)\)</span> is calculated as the average across response-level sequence probabilities (normalized or otherwise), and <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> denotes the full set of clusters of <span class="math notranslate nohighlight">\(\{y_i\} \cup \tilde{\mathbf{y}}_i\)</span>.</p>
<p>To ensure that we have a normalized confidence score with <span class="math notranslate nohighlight">\([0,1]\)</span> support and with higher values corresponding to higher confidence, we implement the following normalization to arrive at <em>ormalized Semantic Negentropy</em> (NSN):</p>
<div class="math notranslate nohighlight">
\[NSN(y_i; \tilde{\mathbf{y}}_i) = 1 - \frac{SE(y_i; \tilde{\mathbf{y}}_i)}{\log m},\]</div>
<p>where <span class="math notranslate nohighlight">\(\log m\)</span> is included to normalize the support. For more on semantic entropy, refer to <a class="reference external" href="https://www.nature.com/articles/s41586-024-07421-0">Farquhar et al., 2024</a>; <a class="reference external" href="https://arxiv.org/pdf/2302.09664">Kuhn et al., 2023</a>, and for more on our normalized version, refer to <a class="reference external" href="https://arxiv.org/abs/2504.19254">Bouchard &amp; Chauhan, 2025</a>.</p>
</section>
<section id="Semantic-Density">
<h3>Semantic Density<a class="headerlink" href="#Semantic-Density" title="Link to this heading">#</a></h3>
<p>Semantic Density (SD) approximates a probability density function (PDF) in semantic space for estimating response correctness. Given a prompt <span class="math notranslate nohighlight">\(x\)</span> with candidate response <span class="math notranslate nohighlight">\(y_*\)</span>, the objective is to construct a PDF that assigns higher density to regions in the semantic space that correspond to correct responses. We begin by sampling <span class="math notranslate nohighlight">\(M\)</span> unique reference responses <span class="math notranslate nohighlight">\(y_i\)</span> (for <span class="math notranslate nohighlight">\(i = 1, 2, \dots, M\)</span>) conditioned on <span class="math notranslate nohighlight">\(x\)</span>. For any pair of responses <span class="math notranslate nohighlight">\(y_i, y_j\)</span> with
corresponding embeddings <span class="math notranslate nohighlight">\(v_i, v_j\)</span>, the semantic distance is estimated as</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}(\Vert v_i,v_j \Vert^2) = p_c(y_i, y_j | x) + \dfrac{1}{2} \cdot p_n(y_i, y_j | x)\]</div>
<p>where <span class="math notranslate nohighlight">\(p_c, p_n\)</span> denote the contradiction and neutrality scores returned by a natural language inference (NLI) model, respectively. This estimated distance is incorporated in the kernel function <span class="math notranslate nohighlight">\(K\)</span> to smooth out the reference responses into a continuous distribution. The kernel function value can be obtained as</p>
<div class="math notranslate nohighlight">
\[K(v_*, v_i) = (1 - \mathbb{E}(\Vert v_* - v_i \Vert^2))\mathbf{1}_{\mathbb{E}(\Vert v_* - v_i \Vert) \leq 1}\]</div>
<p>where <span class="math notranslate nohighlight">\(\bf{1}\)</span> is the indicator function such that <span class="math notranslate nohighlight">\(\bf{1}_{\text{condition}} = 1\)</span> when the condition holds and <span class="math notranslate nohighlight">\(0\)</span> otherwise. The final semantic density score is computed as</p>
<div class="math notranslate nohighlight">
\[SD(y_* | x) = \dfrac{1}{\sum^M_{i=1}\sqrt[L_i]{p(y_i|x)}}\sum^M_{i=1}\sqrt[L_i]{p(y_i|x)}K(v_* - v_i)\]</div>
<p>where <span class="math notranslate nohighlight">\(L_i\)</span> denotes the length of <span class="math notranslate nohighlight">\(y_i\)</span>.</p>
</section>
<section id="P(True)-(p_true)">
<h3>P(True) (<code class="docutils literal notranslate"><span class="pre">p_true</span></code>)<a class="headerlink" href="#P(True)-(p_true)" title="Link to this heading">#</a></h3>
<p>The P(True) presents an LLM with a concatenation of a question and its own previous response. The LLM is asked to classify this statement as ‚ÄúTrue‚Äù or ‚ÄúFalse.‚Äù We derive this confidence score directly from the model‚Äôs token probability for answering ‚ÄúTrue‚Äù (or equivalently, 1-P(‚ÄúFalse‚Äù) if the model answers ‚ÄúFalse‚Äù). For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2207.05221">Kadavath et al., 2022</a>.</p>
<p>¬© 2025 CVS Health and/or one of its affiliates. All rights reserved.</p>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="semantic_density_demo.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">üéØ Semantic Density</p>
      </div>
    </a>
    <a class="right-next"
       href="white_box_single_generation_demo.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">üéØ White-Box Uncertainty Quantification</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#üìä-What-You'll-Do-in-This-Demo">üìä What You‚Äôll Do in This Demo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#‚öñÔ∏è-Advantages-&amp;-Limitations">‚öñÔ∏è Advantages &amp; Limitations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#WhiteBoxUQ()---Generate-LLM-responses-and-compute-token-probability-based-confidence-scores-for-each-response."><code class="docutils literal notranslate"><span class="pre">WhiteBoxUQ()</span></code> - Generate LLM responses and compute token-probability-based confidence scores for each response.</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#üìã-Class-Attributes">üìã Class Attributes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#üîç-Parameter-Groups">üîç Parameter Groups</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#üîÑ-Class-Methods">üîÑ Class Methods</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#3.1-Filtered-LLM-Accuracy-Evaluation">3.1 Filtered LLM Accuracy Evaluation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#3.2-Precision,-Recall,-F1-Score-of-Hallucination-Detection">3.2 Precision, Recall, F1-Score of Hallucination Detection</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Monte-Carlo-Sequence-Probability-(monte_carlo_probability)">Monte Carlo Sequence Probability (<code class="docutils literal notranslate"><span class="pre">monte_carlo_probability</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Consistency-and-Confidence-Approach-(CoCoA)-(consistency_and_confidence)">Consistency and Confidence Approach (CoCoA) (<code class="docutils literal notranslate"><span class="pre">consistency_and_confidence</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Normalized-Semantic-Negentropy">Normalized Semantic Negentropy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Semantic-Density">Semantic Density</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#P(True)-(p_true)">P(True) (<code class="docutils literal notranslate"><span class="pre">p_true</span></code>)</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/_notebooks/examples/white_box_multi_generation_demo.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2025, CVS Health.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>