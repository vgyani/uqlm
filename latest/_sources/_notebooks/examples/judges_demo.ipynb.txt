{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ LLM-as-a-Judge\n",
    "\n",
    "<div style=\"background-color: rgba(200, 200, 200, 0.1); padding: 20px; border-radius: 8px; margin-bottom: 20px; border: 1px solid rgba(127, 127, 127, 0.2); max-width: 100%; overflow-wrap: break-word;\">\n",
    "  <p style=\"font-size: 16px; line-height: 1.6\">\n",
    "   LLM-as-a-Judge scorers use one or more LLMs to evaluate the reliability of the original LLM's response. They offer high customizability through prompt engineering and the choice of judge LLM(s). Below is a list of the available scorers:\n",
    "  </p>\n",
    "\n",
    "*   Categorical LLM-as-a-Judge ([Manakul et al., 2023](https://arxiv.org/abs/2303.08896); [Chen & Mueller, 2023](https://arxiv.org/abs/2308.16175); [Luo et al., 2023](https://arxiv.org/abs/2303.15621))\n",
    "*   Continuous LLM-as-a-Judge ([Xiong et al., 2024](https://arxiv.org/abs/2306.13063))\n",
    "*   Likert Scale LLM-as-a-Judge ([Bai et al., 2023](https://arxiv.org/pdf/2306.04181))\n",
    "*   Panel of LLM Judges ([Verga et al., 2024](https://arxiv.org/abs/2404.18796))\n",
    "    \n",
    "</div>\n",
    "\n",
    "## üìä What You'll Do in This Demo\n",
    "\n",
    "\n",
    "<div style=\"display: flex; margin-bottom: 15px; align-items: center\">\n",
    "  <div style=\"background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0\"><strong>1</strong></div>\n",
    "  <div>\n",
    "    <p style=\"margin: 0; font-weight: bold\"><a href=#section1>Set up LLM and prompts.</a></p>\n",
    "    <p style=\"margin: 0; color: rgba(95, 99, 104, 0.8)\">Set up LLM instance and load example data prompts.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; margin-bottom: 15px; align-items: center\">\n",
    "  <div style=\"background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0\"><strong>2</strong></div>\n",
    "  <div>\n",
    "    <p style=\"margin: 0; font-weight: bold\"><a href=#section2>Generate LLM Responses and Confidence Scores</a></p>\n",
    "    <p style=\"margin: 0; color: rgba(95, 99, 104, 0.8)\">Generate and score LLM responses to the example questions using the <code>LLMPanel()</code> class.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; margin-bottom: 25px; align-items: center\">\n",
    "  <div style=\"background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0\"><strong>3</strong></div>\n",
    "  <div>\n",
    "    <p style=\"margin: 0; font-weight: bold\"><a href=#section3>Evaluate Hallucination Detection Performance</a></p>\n",
    "    <p style=\"margin: 0; color: rgba(95, 99, 104, 0.8)\">Compute precision, recall, and F1-score of hallucination detection.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "## ‚öñÔ∏è Advantages & Limitations\n",
    "\n",
    "<div style=\"display: flex; gap: 20px\">\n",
    "  <div style=\"flex: 1; background-color: rgba(0, 200, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(0, 200, 0, 0.2)\">\n",
    "    <h3 style=\"color: #2e8b57; margin-top: 0\">Pros</h3>\n",
    "    <ul style=\"margin-bottom: 0\">\n",
    "      <li><strong>Universal Compatibility:</strong> Works with any LLM.</li>\n",
    "      <li><strong>Highly Customizable:</strong> Use any LLM as a judge and tailor instruction prompts for specific use cases.</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"flex: 1; background-color: rgba(200, 0, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(200, 0, 0, 0.2)\">\n",
    "    <h3 style=\"color: #b22222; margin-top: 0\">Cons</h3>\n",
    "    <ul style=\"margin-bottom: 0\">\n",
    "      <li><strong>Added cost:</strong> Requires additional LLM calls for the judge LLM(s).</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from uqlm import LLMPanel\n",
    "from uqlm.utils import load_example_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up LLM and Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we will illustrate this approach using a set of multiple choice  questions from the [AI2-ARC benchmark](https://arxiv.org/abs/1803.05457). To implement with your use case, simply **replace the example prompts with your data**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset - ai2_arc...\n",
      "Processing dataset...\n",
      "Dataset ready!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which statement best explains why photosynthes...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which piece of safety equipment is used to kee...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meiosis is a type of cell division in which ge...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which characteristic describes the texture of ...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which best describes the structure of an atom?...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer\n",
       "0  Which statement best explains why photosynthes...      A\n",
       "1  Which piece of safety equipment is used to kee...      B\n",
       "2  Meiosis is a type of cell division in which ge...      D\n",
       "3  Which characteristic describes the texture of ...      D\n",
       "4  Which best describes the structure of an atom?...      B"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load example dataset (ai2_arc)\n",
    "ai2_arc = load_example_dataset(\"ai2_arc\", n=75)\n",
    "ai2_arc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define prompts\n",
    "MCQ_INSTRUCTION = \"You will be given a multiple choice question. Return only the letter of the response with no additional text or explanation.\\n\"\n",
    "prompts = [MCQ_INSTRUCTION + prompt for prompt in ai2_arc.question]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use `ChatOllama` to instantiate our LLMs, but any [LangChain Chat Model](https://js.langchain.com/docs/integrations/chat/) may be used. Be sure to **replace with your LLM of choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install langchain-ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "ollama_llama = ChatOllama(model=\"llama2\")\n",
    "ollama_mistral = ChatOllama(model=\"mistral\")\n",
    "ollama_qwen = ChatOllama(model=\"qwen3\")\n",
    "# ollama_deepseek = ChatOllama(model=\"deepseek-r1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative setup with API models\n",
    "\n",
    "## ChatVertexAI example\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install langchain-google-vertexai\n",
    "# from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "# gemini_pro = ChatVertexAI(model_name=\"gemini-2.5-pro\")\n",
    "# gemini_flash = ChatVertexAI(model_name=\"gemini-2.5-flash\")\n",
    "\n",
    "\n",
    "## AzureChatOpenAI example\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install langchain-openai\n",
    "\n",
    "# # User to populate .env file with API credentials\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# load_dotenv(find_dotenv())\n",
    "# original_llm = AzureChatOpenAI(\n",
    "#     deployment_name=\"gpt-4o\",\n",
    "#     openai_api_type=\"azure\",\n",
    "#     openai_api_version=\"2024-02-15-preview\",\n",
    "#     temperature=1,  # User to set temperature\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate responses and confidence scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LLMPanel()` - Class for aggregating multiple instances of LLMJudge using average, min, max, or majority voting\n",
    "\n",
    "![Sample Image](https://raw.githubusercontent.com/cvs-health/uqlm/develop/assets/images/judges_graphic.png)\n",
    "\n",
    "#### üìã Class Attributes\n",
    "\n",
    "<table style=\"border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);\">\n",
    "  <tr>\n",
    "    <th style=\"background-color: rgba(200, 200, 200, 0.2); width: 20%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);\">Parameter</th>\n",
    "    <th style=\"background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);\">Type & Default</th>\n",
    "    <th style=\"background-color: rgba(200, 200, 200, 0.2); width: 55%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);\">Description</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">judges</td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">list of LLMJudge or BaseChatModel<br><code></code></td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">Judges to use. If BaseChatModel, LLMJudge is instantiated using default parameters.</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td style=\"font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">llm</td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">BaseChatModel<br><code>default=None</code></td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">A langchain llm `BaseChatModel`. User is responsible for specifying temperature and other relevant parameters to the constructor of the provided `llm` object.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">system_prompt</td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">str or None<br><code>default=\"You are a helpful assistant.\"</code></td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">Optional argument for user to provide custom system prompt for the LLM.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">max_calls_per_min</td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">int<br><code>default=None</code></td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">Specifies how many API calls to make per minute to avoid rate limit errors. By default, no limit is specified.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">explanations</td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">bool<br><code>default=False</code></td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">Whether to include explanations from judges alongside scores. When True, judges provide reasoning for their scores.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">additional_context</td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">str or None<br><code>default=None</code></td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">Optional argument to provide additional context to inform LLM-as-a-Judge evaluations.</td>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "#### üîç Parameter Groups\n",
    "\n",
    "<div style=\"display: flex; gap: 20px; margin-bottom: 20px\">\n",
    "  <div style=\"flex: 1; padding: 10px; background-color: rgba(0, 100, 200, 0.1); border-radius: 5px; border: 1px solid rgba(0, 100, 200, 0.2);\">\n",
    "    <p style=\"font-weight: bold\">üß† LLM-Specific</p>\n",
    "    <ul>\n",
    "      <li><code>llm</code></li>\n",
    "      <li><code>system_prompt</code></li>\n",
    "    </ul>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 10px; background-color: rgba(0, 200, 0, 0.1); border-radius: 5px; border: 1px solid rgba(0, 200, 0, 0.2);\">\n",
    "    <p style=\"font-weight: bold\">üìä Confidence Scores</p>\n",
    "    <ul>\n",
    "      <li><code>judges</code></li>\n",
    "      <li><code>explanations</code></li>        \n",
    "      <li><code>additional_context</code></li>\n",
    "    </ul>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 10px; background-color: rgba(200, 0, 200, 0.1); border-radius: 5px; border: 1px solid rgba(200, 0, 200, 0.2);\">\n",
    "    <p style=\"font-weight: bold\">‚ö° Performance</p>\n",
    "    <ul>\n",
    "      <li><code>max_calls_per_min</code></li>\n",
    "    </ul>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "#### üíª Usage Examples\n",
    "\n",
    "```python\n",
    "# Basic usage with single self-judge parameters\n",
    "panel = LLMPanel(llm=llm, judges=[llm])\n",
    "\n",
    "# Using two judges with default parameters\n",
    "panel = LLMPanel(llm=llm, judges=[llm, llm2])\n",
    "\n",
    "# Using two judges with default parameters\n",
    "panel = LLMPanel(llm=llm, judges=[llm, llm2])\n",
    "\n",
    "# Using judges with explanations enabled\n",
    "panel_with_explanations = LLMPanel(\n",
    "    llm=llm, judges=[llm, llm2], explanations=True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "judges = [ollama_mistral, ollama_llama, ollama_qwen]\n",
    "additional_context = \"You are an expert in general-knowledge reasoning questions. Your task is to evaluate the correctness of the proposed answers to the provided questions.\"\n",
    "\n",
    "# Option 1: With explanations\n",
    "panel = LLMPanel(llm=ollama_mistral, judges=judges, additional_context=additional_context, explanations=True)\n",
    "\n",
    "# Option 2: Without explanations\n",
    "# panel = LLMPanel(llm=ollama_mistral, judges=judges, additional_context=additional_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Class Methods\n",
    "\n",
    "<table style=\"border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);\">\n",
    "  <tr>\n",
    "    <th style=\"background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);\">Method</th>\n",
    "    <th style=\"background-color: rgba(200, 200, 200, 0.2); width: 75%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);\">Description & Parameters</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">LLMPanel.generate_and_score</td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">\n",
    "      <p>Generate responses to provided prompts and use panel to of judges to score responses for correctness.</p>\n",
    "      <p><strong>Parameters:</strong></p>\n",
    "      <ul>\n",
    "        <li><code>prompts</code> - (<strong>list of str</strong>) A list of input prompts for the model.</li>\n",
    "      </ul>\n",
    "      <p><strong>Returns:</strong> <code>UQResult</code> containing data (prompts, responses, sampled responses, and confidence scores) and metadata</p>\n",
    "      <div style=\"background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;\">\n",
    "        <strong>üí° Best For:</strong> Complete end-to-end uncertainty quantification when starting with prompts.\n",
    "      </div>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">LLMPanel.score</td>\n",
    "    <td style=\"padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);\">\n",
    "      <p>Use panel to of judges to score provided responses for correctness. Use if responses are already generated. Otherwise, use `generate_and_score`.</p>\n",
    "      <p><strong>Parameters:</strong></p>\n",
    "      <ul>\n",
    "        <li><code>prompts</code> - (<strong>list of str</strong>) A list of input prompts for the model.</li>\n",
    "        <li><code>responses</code> - (<strong>list of str</strong>) A list of LLM responses for the prompts.</li>\n",
    "      </ul>\n",
    "      <p><strong>Returns:</strong> <code>UQResult</code> containing data (responses and confidence scores) and metadata</p>\n",
    "      <div style=\"background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;\">\n",
    "        <strong>üí° Best For:</strong> Computing uncertainty scores when responses are already generated elsewhere.\n",
    "      </div>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5525fe46a9547c4a66a9ea7d0eecc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await panel.generate_and_score(prompts=prompts)\n",
    "\n",
    "# option 2: provide pre-generated responses with score method\n",
    "# result = await panel.score(prompts=prompts, responses=responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>judge_1</th>\n",
       "      <th>judge_1_explanation</th>\n",
       "      <th>judge_2</th>\n",
       "      <th>judge_2_explanation</th>\n",
       "      <th>judge_3</th>\n",
       "      <th>judge_3_explanation</th>\n",
       "      <th>avg</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>A) Sunlight is the source of energy for nearl...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No explanation provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The answer correctly identifies that sunlight ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Photosynthesis is foundational because it conv...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>C) breathing mask</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No explanation provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The breathing mask is used to filter air and p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The breathing mask (B) is designed to filter a...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>D) ovary cells</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The question specifically states that meiosis ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Meiosis occurs in germ cells (sex cells) of or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Meiosis occurs in germ cells to produce haploi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No explanation provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question asks for the texture of a kitten'...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question asks about the texture of a kitte...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>C) a network of interacting positive and nega...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>While the answer \"a network of interacting pos...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The structure of an atom is indeed a network o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The correct structure of an atom is a nucleus ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  You will be given a multiple choice question. ...   \n",
       "1  You will be given a multiple choice question. ...   \n",
       "2  You will be given a multiple choice question. ...   \n",
       "3  You will be given a multiple choice question. ...   \n",
       "4  You will be given a multiple choice question. ...   \n",
       "\n",
       "                                            response  judge_1  \\\n",
       "0   A) Sunlight is the source of energy for nearl...      1.0   \n",
       "1                                  C) breathing mask      1.0   \n",
       "2                                     D) ovary cells      NaN   \n",
       "3                                                  D      1.0   \n",
       "4   C) a network of interacting positive and nega...      0.5   \n",
       "\n",
       "                                 judge_1_explanation  judge_2  \\\n",
       "0                            No explanation provided      1.0   \n",
       "1                            No explanation provided      1.0   \n",
       "2  The question specifically states that meiosis ...      1.0   \n",
       "3                            No explanation provided      1.0   \n",
       "4  While the answer \"a network of interacting pos...      1.0   \n",
       "\n",
       "                                 judge_2_explanation  judge_3  \\\n",
       "0  The answer correctly identifies that sunlight ...      1.0   \n",
       "1  The breathing mask is used to filter air and p...      0.0   \n",
       "2  Meiosis occurs in germ cells (sex cells) of or...      1.0   \n",
       "3  The question asks for the texture of a kitten'...      1.0   \n",
       "4  The structure of an atom is indeed a network o...      0.0   \n",
       "\n",
       "                                 judge_3_explanation       avg  max  min  \\\n",
       "0  Photosynthesis is foundational because it conv...  1.000000  1.0  1.0   \n",
       "1  The breathing mask (B) is designed to filter a...  0.666667  1.0  0.0   \n",
       "2  Meiosis occurs in germ cells to produce haploi...       NaN  NaN  NaN   \n",
       "3  The question asks about the texture of a kitte...  1.000000  1.0  1.0   \n",
       "4  The correct structure of an atom is a nucleus ...  0.500000  1.0  0.0   \n",
       "\n",
       "   median  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     NaN  \n",
       "3     1.0  \n",
       "4     0.5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result.to_df()\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate Hallucination Detection Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate hallucination detection performance, we 'grade' the responses against an answer key. Note the `check_letter_match` function is specific to our task (multiple choice). **If you are using your own prompts/questions, update the grading method accordingly**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>judge_1</th>\n",
       "      <th>judge_1_explanation</th>\n",
       "      <th>judge_2</th>\n",
       "      <th>judge_2_explanation</th>\n",
       "      <th>judge_3</th>\n",
       "      <th>judge_3_explanation</th>\n",
       "      <th>avg</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "      <th>answer</th>\n",
       "      <th>response_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>A) Sunlight is the source of energy for nearl...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No explanation provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The answer correctly identifies that sunlight ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Photosynthesis is foundational because it conv...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>C) breathing mask</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No explanation provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The breathing mask is used to filter air and p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The breathing mask (B) is designed to filter a...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>D) ovary cells</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The question specifically states that meiosis ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Meiosis occurs in germ cells (sex cells) of or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Meiosis occurs in germ cells to produce haploi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No explanation provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question asks for the texture of a kitten'...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question asks about the texture of a kitte...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You will be given a multiple choice question. ...</td>\n",
       "      <td>C) a network of interacting positive and nega...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>While the answer \"a network of interacting pos...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The structure of an atom is indeed a network o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The correct structure of an atom is a nucleus ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  You will be given a multiple choice question. ...   \n",
       "1  You will be given a multiple choice question. ...   \n",
       "2  You will be given a multiple choice question. ...   \n",
       "3  You will be given a multiple choice question. ...   \n",
       "4  You will be given a multiple choice question. ...   \n",
       "\n",
       "                                            response  judge_1  \\\n",
       "0   A) Sunlight is the source of energy for nearl...      1.0   \n",
       "1                                  C) breathing mask      1.0   \n",
       "2                                     D) ovary cells      NaN   \n",
       "3                                                  D      1.0   \n",
       "4   C) a network of interacting positive and nega...      0.5   \n",
       "\n",
       "                                 judge_1_explanation  judge_2  \\\n",
       "0                            No explanation provided      1.0   \n",
       "1                            No explanation provided      1.0   \n",
       "2  The question specifically states that meiosis ...      1.0   \n",
       "3                            No explanation provided      1.0   \n",
       "4  While the answer \"a network of interacting pos...      1.0   \n",
       "\n",
       "                                 judge_2_explanation  judge_3  \\\n",
       "0  The answer correctly identifies that sunlight ...      1.0   \n",
       "1  The breathing mask is used to filter air and p...      0.0   \n",
       "2  Meiosis occurs in germ cells (sex cells) of or...      1.0   \n",
       "3  The question asks for the texture of a kitten'...      1.0   \n",
       "4  The structure of an atom is indeed a network o...      0.0   \n",
       "\n",
       "                                 judge_3_explanation       avg  max  min  \\\n",
       "0  Photosynthesis is foundational because it conv...  1.000000  1.0  1.0   \n",
       "1  The breathing mask (B) is designed to filter a...  0.666667  1.0  0.0   \n",
       "2  Meiosis occurs in germ cells to produce haploi...       NaN  NaN  NaN   \n",
       "3  The question asks about the texture of a kitte...  1.000000  1.0  1.0   \n",
       "4  The correct structure of an atom is a nucleus ...  0.500000  1.0  0.0   \n",
       "\n",
       "   median answer  response_correct  \n",
       "0     1.0      A              True  \n",
       "1     1.0      B             False  \n",
       "2     NaN      D              True  \n",
       "3     1.0      D              True  \n",
       "4     0.5      B             False  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate correct answers and grade responses\n",
    "result_df[\"answer\"] = ai2_arc.answer\n",
    "\n",
    "\n",
    "def check_letter_match(response: str, answer: str):\n",
    "    return response.strip().lower()[0] == answer[0].lower()\n",
    "\n",
    "\n",
    "result_df[\"response_correct\"] = [check_letter_match(r, a) for r, a in zip(result_df[\"response\"], ai2_arc[\"answer\"])]\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge 1 precision: 0.7083333333333334\n",
      "Judge 1 recall: 0.6938775510204082\n",
      "Judge 1 f1-score: 0.7010309278350515\n",
      " \n",
      "Judge 2 precision: 0.6712328767123288\n",
      "Judge 2 recall: 1.0\n",
      "Judge 2 f1-score: 0.8032786885245902\n",
      " \n",
      "Judge 3 precision: 0.9074074074074074\n",
      "Judge 3 recall: 1.0\n",
      "Judge 3 f1-score: 0.9514563106796117\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# evaluate precision, recall, and f1-score of Semantic Entropy's predictions of correctness\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "for ind in [1, 2, 3]:\n",
    "    y_pred = [(s > 0) * 1 for s in result_df[f\"judge_{str(ind)}\"]]\n",
    "    y_true = result_df.response_correct\n",
    "    print(f\"Judge {ind} precision: {precision_score(y_true=y_true, y_pred=y_pred)}\")\n",
    "    print(f\"Judge {ind} recall: {recall_score(y_true=y_true, y_pred=y_pred)}\")\n",
    "    print(f\"Judge {ind} f1-score: {f1_score(y_true=y_true, y_pred=y_pred)}\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scorer Definitions\n",
    "Under the LLM-as-a-Judge approach, either the same LLM that was used for generating the original responses or a different LLM is asked to form a judgment about a pre-generated response. Below, we define two LLM-as-a-Judge scorer templates. \n",
    "### Ternary Judge Template (`true_false_uncertain`)\n",
    "We follow the approach proposed by [Chen & Mueller, 2023](https://arxiv.org/abs/2308.16175) in which an LLM is instructed to score a question-response concatenation as either  *incorrect*, *uncertain*, or *correct* using a carefully constructed prompt. These categories are respectively mapped to numerical scores of 0, 0.5, and 1. We denote the LLM-as-a-judge scorers as $J: \\mathcal{Y} \\xrightarrow[]{} \\{0, 0.5, 1\\}$. Formally, we can write this scorer function as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "J(y_i) = \\begin{cases}\n",
    "    0 & \\text{LLM states response is incorrect} \\\\\n",
    "    0.5 & \\text{LLM states that it is uncertain} \\\\\n",
    "    1 & \\text{LLM states response is correct}.\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "### Binary Judge Template (`true_false`)\n",
    "We modify the ternary approach above and include only two categories: Correct or Incorrect, which respectively map to 1 and 0.\n",
    "\n",
    "### Continuous Judge Template (`continuous`)\n",
    "For the continuous template, the LLM is asked to directly score a question-response concatenation's correctness on a scale of 0 to 1. \n",
    "\n",
    "### Likert-Scale Judge Template (`likert`)\n",
    "Here the judge is asked to score a question-response concatenation on a 5-point likert scale. We convert these likert scores to a [0,1] scale as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "J(y_i) = \\begin{cases}\n",
    "    0 & \\text{LLM states response is completely incorrect} \\\\\n",
    "    0.25 & \\text{LLM states that it is mostly incorrect} \\\\\n",
    "    0.5 & \\text{LLM states that it is partially correct} \\\\\n",
    "    0.75 & \\text{LLM states that it is mostly correct} \\\\\n",
    "    0.1 & \\text{LLM states that it is completely correct} \n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬© 2025 CVS Health and/or one of its affiliates. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "uqlm_my_test",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "uqlm_my_test",
   "language": "python",
   "name": "uqlm_my_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
